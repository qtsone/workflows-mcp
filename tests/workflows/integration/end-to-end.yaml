name: integration-end-to-end
description: |
  Integration test demonstrating common workflow patterns:
  1. Variable resolution across namespaces (inputs, metadata, blocks)
  2. Conditional execution based on results
  3. File operations with templates
  4. State management across phases
  5. Parallel execution where possible
  6. Block status detection
tags: [test, integration, end-to-end]
inputs:
  project_name:
    type: str
    default: "TestProject"
    description: "Project name for the workflow"

  working_dir:
    type: str
    default: "/tmp/integration-test"
    description: "Directory for test outputs"

blocks:
  - id: init_state
    description: "Initialize workflow state"
    type: WriteJSONState
    inputs:
      path: "${inputs.working_dir}/state.json"
      data:
        project: "${inputs.project_name}"
        phase: "init"
        workflow: "${metadata.workflow_name}"
      create_parents: true

  - id: gen_data1
    description: "Generate data in parallel"
    type: Shell
    inputs:
      command: printf "data1"
    depends_on: [init_state]

  - id: gen_data2
    description: "Generate data in parallel"
    type: Shell
    inputs:
      command: printf "data2"
    depends_on: [init_state]

  - id: update_state
    description: "Update state after parallel generation"
    type: MergeJSONState
    inputs:
      path: "${inputs.working_dir}/state.json"
      updates:
        phase: "generation_complete"
        data1: "${blocks.gen_data1.outputs.stdout}"
        data2: "${blocks.gen_data2.outputs.stdout}"
    depends_on: [gen_data1, gen_data2]

  - id: render_report
    description: "Render report (depends on both data sources)"
    type: RenderTemplate
    inputs:
      template: |
        # {{ project }}

        Workflow: {{ workflow }}
        Timestamp: {{ timestamp }}

        ## Data Streams
        - Stream 1: {{ data1 }}
        - Stream 2: {{ data2 }}

        ## Status
        Phase: {{ phase }}
      variables:
        project: "${inputs.project_name}"
        workflow: "${metadata.workflow_name}"
        timestamp: "${metadata.start_time}"
        data1: "${blocks.gen_data1.outputs.stdout}"
        data2: "${blocks.gen_data2.outputs.stdout}"
        phase: "report_generation"
      output_path: "${inputs.working_dir}/report.md"
    depends_on: [update_state]

  - id: validate_success
    description: "Validate successful completion"
    type: Shell
    inputs:
      command: echo "validation_passed"
    condition: >
      ${blocks.gen_data1.succeeded} and ${blocks.gen_data2.succeeded} and ${blocks.render_report.succeeded}
    depends_on:
      - block: render_report
        required: false

  - id: validate_failure
    description: "Validate failure scenario"
    type: Shell
    inputs:
      command: echo "validation_failed"
    condition: >
      ${blocks.gen_data1.failed} or ${blocks.gen_data2.failed} or ${blocks.render_report.failed}
    depends_on:
      - block: render_report
        required: false

  - id: final_state
    description: "Finalize workflow state"
    type: MergeJSONState
    inputs:
      path: "${inputs.working_dir}/state.json"
      updates:
        phase: "complete"
        validation_passed: "${blocks.validate_success.succeeded}"
    depends_on:
      - block: validate_success
        required: false
      - block: validate_failure
        required: false

  - id: read_final_state
    description: "Read final state"
    type: ReadJSONState
    inputs:
      path: "${inputs.working_dir}/state.json"
    depends_on: [final_state]

  - id: read_report
    type: ReadFile
    inputs:
      path: "${inputs.working_dir}/report.md"
    depends_on: [final_state]

  - id: cleanup
    description: "Cleanup test directory"
    type: Shell
    inputs:
      command: |
        [ -d "${inputs.working_dir}" ] && rm -rf "${inputs.working_dir}" || echo "Error: Test directory does not exist"
    depends_on: [read_final_state, read_report]

outputs:
  project_name: "${inputs.project_name}"
  workflow_name: "${metadata.workflow_name}"
  data1: "${blocks.gen_data1.outputs.stdout}"
  data2: "${blocks.gen_data2.outputs.stdout}"
  report_content: "${blocks.read_report.outputs.content}"
  final_phase: "${blocks.read_final_state.outputs.data.phase}"
  validation_passed: "${blocks.validate_success.succeeded}"
  all_blocks_succeeded: >
    ${blocks.gen_data1.succeeded} and ${blocks.gen_data2.succeeded} and ${blocks.render_report.succeeded} and ${blocks.validate_success.succeeded} and ${blocks.cleanup.succeeded}
