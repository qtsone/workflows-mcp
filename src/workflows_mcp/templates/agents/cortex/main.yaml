# =============================================================================
# CORTEX Cell - The Fundamental Cognitive Unit (v2)
# =============================================================================
#
# The cell is the spawnable cognitive unit that phases invoke when they
# need to investigate uncertainty. It handles:
#   1. Cycle detection (query hash checking)
#   2. Depth tracking (for cognitive spawning - investigations)
#   3. Iteration tracking (for task completion - ACT continuation)
#   4. Task registration (category: cortex-cell)
#   5. Phase orchestration (categorize → gather → reason → act)
#   6. Pipeline configuration flow with override merging
#   7. Synthesis storage in task.data for child querying
#
# Key v2 Changes:
#   - ALL phases always run (no skipping)
#   - Merged ANALYZE + SYNTHESIZE into REASON phase
#   - Category → pipeline_config via mapping table
#   - Config override: later phases can update config based on discoveries
#   - Fractal continuation: ACT can spawn continuation (same depth, iter+1)
#   - Two counters: depth (investigations) vs iterations (task completion)
#
# Each phase follows the universal fractal pattern and can spawn child cells
# when uncertain. The reason phase queries all child cells to merge their
# findings.
#
# =============================================================================

name: cortex-cell
description: |
  CORTEX Cell - the fundamental cognitive unit. Processes queries through
  the complete cognitive cycle: categorize → gather → reason → act.
  ALL phases always run. Can be spawned by any phase that encounters uncertainty.

tags: [agent, cortex, cell, fractal, recursive, v2]

inputs:
  prompt:
    type: str
    description: The detailed task description.
    required: true

  context:
    type: dict
    description: |
      Shared context:
      - repo_path: Working directory
      - parent_prompt: Query that spawned this cell
      - spawning_phase: Which phase spawned this cell
    default: {}

  depth:
    type: num
    description: Current cell depth (0 = root).
    default: 0

  max_depth:
    type: num
    description: Maximum investigation depth (cognitive spawning for sub-questions).
    default: 5

  iterations:
    type: num
    description: Current task completion attempt (ACT continuation counter).
    default: 0

  max_iterations:
    type: num
    description: Maximum continuation attempts for incomplete tasks.
    default: 3

  confidence_threshold:
    type: num
    description: Minimum confidence to proceed without investigation.
    default: 0.95

  state:
    type: str
    description: Path to SQLite state database. Created if empty.
    default: ""

  parent_id:
    type: str
    description: Parent task ID in the task tree.
    default: ""

  profile:
    type: str
    description: LLM profile to use.
    default: "default"

  capabilities:
    type: list
    description: |
      Available capabilities registry (flat list).
      Each capability has: name, description, inputs, requires (permission).
      Capabilities are filtered based on permissions before being passed to phases.
    default:
      - name: cortex-gather-files
        description: Read files matching glob patterns
        inputs:
          patterns: "list[str] - Glob patterns to match (required)"
          base_path: "str - Base directory (optional)"
          mode: "str - outline|full|summary (optional)"
          max_files: "int - Max files to read (optional)"
        requires: read

      - name: cortex-gather-search
        description: Search codebase with regex
        inputs:
          pattern: "str - Regex pattern to search (required)"
          path: "str - Directory to search (optional)"
          file_type: "str - File extension filter e.g. py, js (optional)"
          max_matches: "int - Max results to return (optional)"
        requires: read

      - name: cortex-action-write
        description: Create or overwrite a file
        inputs:
          path: "str - File path to write (required)"
          content: "str - File content (required)"
          overwrite: "bool - Allow overwriting existing file (optional)"
        requires: write

      - name: cortex-action-edit
        description: Edit an existing file with operations
        inputs:
          path: "str - File path to edit (required)"
          operations: "list - Edit operations [{type, old_string, new_string}] (required)"
          backup: "bool - Create backup before editing (optional)"
          dry_run: "bool - Preview changes without applying (optional)"
        requires: write

      - name: cortex-action-execute
        description: Execute a shell command
        inputs:
          command: "str - Command to execute (required)"
          working_dir: "str - Working directory (optional)"
          timeout: "int - Timeout in seconds (optional)"
        requires: execute

  permissions:
    type: dict
    description: |
      Permission flags controlling which capabilities are available.
      Capabilities are filtered based on these flags before phases receive them.
    default:
      read: true
      write: false
      execute: false

  prompt_history:
    type: list
    description: Hashes of ancestor queries (for cycle detection).
    default: []

blocks:
  - id: init
    description: Compute query hash, check for cycles, depth, and iteration limits.
    type: Shell
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import hashlib
        import os

        prompt = os.environ.get('PROMPT', '')
        depth = int(os.environ.get('DEPTH', '0'))
        max_depth = int(os.environ.get('MAX_DEPTH', '5'))
        iterations = int(os.environ.get('ITERATIONS', '0'))
        max_iterations = int(os.environ.get('MAX_ITERATIONS', '3'))
        history_json = os.environ.get('PROMPT_HISTORY', '[]')

        try:
            prompt_history = json.loads(history_json) if history_json else []
        except json.JSONDecodeError:
            prompt_history = []

        hash = hashlib.sha256(prompt.encode()).hexdigest()[:16]

        depth_exceeded = depth >= max_depth
        iterations_exceeded = iterations >= max_iterations
        cycle_detected = hash in prompt_history
        terminate = depth_exceeded or cycle_detected or iterations_exceeded

        new_history = prompt_history + [hash]

        if depth_exceeded:
            reason = 'depth_exceeded'
        elif iterations_exceeded:
            reason = 'iterations_exceeded'
        elif cycle_detected:
            reason = 'cycle_detected'
        else:
            reason = None

        result = {
            'hash': hash,
            'depth': depth,
            'iterations': iterations,
            'terminate': terminate,
            'reason': reason,
            'prompt_history': new_history
        }

        print(json.dumps(result))
        EOF
      env:
        PROMPT: "{{ inputs.prompt }}"
        DEPTH: "{{ inputs.depth }}"
        MAX_DEPTH: "{{ inputs.max_depth }}"
        ITERATIONS: "{{ inputs.iterations }}"
        MAX_ITERATIONS: "{{ inputs.max_iterations }}"
        PROMPT_HISTORY: "{{ inputs.prompt_history | tojson }}"

  # ===========================================================================
  # Filter capabilities based on permissions
  # ===========================================================================
  - id: filter_capabilities
    type: Shell
    description: Filter capabilities based on permission flags.
    depends_on: [init]
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        capabilities = json.loads(os.environ.get('CAPABILITIES', '[]'))
        permissions = json.loads(os.environ.get('PERMISSIONS', '{}'))

        # Filter to only capabilities whose required permission is granted
        filtered = [
            cap for cap in capabilities
            if permissions.get(cap.get('requires', 'read'), False)
        ]

        print(json.dumps(filtered))
        EOF
      env:
        CAPABILITIES: "{{ inputs.capabilities | tojson }}"
        PERMISSIONS: "{{ inputs.permissions | tojson }}"

  - id: register
    type: Workflow
    description: Register this cell in the task tree.
    depends_on: [init, filter_capabilities]
    inputs:
      workflow: agent-state-management
      inputs:
        state: "{{ inputs.state }}"
        parent_id: "{{ inputs.parent_id }}"
        task: "CORTEX Cell (depth={{ inputs.depth }}, iter={{ inputs.iterations }})"
        category: "cortex-cell"
        status: "in-progress"
        caller: "cortex-cell"
        data:
          prompt: "{{ inputs.prompt }}"
          hash: "{{ (blocks.init.outputs.stdout | fromjson).hash }}"
          depth: "{{ inputs.depth }}"
          iterations: "{{ inputs.iterations }}"
          spawning_phase: "{{ inputs.context.spawning_phase | default('root') }}"

  - id: early_termination
    type: Shell
    description: Return early termination result.
    depends_on: [init, register]
    condition: "{{ (blocks.init.outputs.stdout | fromjson).terminate }}"
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        reason = os.environ.get('TERMINATION_REASON', 'unknown')

        result = {
            'synthesis': {
                'findings': [],
                'summary': f'Cell terminated: {reason}',
                'recommendations': [],
                'actions_needed': False
            },
            'response': f'Unable to complete: {reason}',
            'categorization': {},
            'actions': {}
        }

        print(json.dumps(result))
        EOF
      env:
        TERMINATION_REASON: "{{ (blocks.init.outputs.stdout | fromjson).reason }}"

  # ===========================================================================
  # PHASE 1: CATEGORIZE - classify query and set pipeline_config
  # ===========================================================================
  - id: categorize
    description: Classify the query and set pipeline configuration from mapping table.
    type: Workflow
    depends_on: [register]
    condition: "{{ not (blocks.init.outputs.stdout | fromjson).terminate }}"
    inputs:
      workflow: cortex-phase-categorize
      inputs:
        prompt: "{{ inputs.prompt }}"
        context: "{{ inputs.context }}"
        depth: "{{ inputs.depth }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        state: "{{ blocks.register.outputs.state }}"
        parent_id: "{{ blocks.register.outputs.task.task_id }}"
        profile: "{{ inputs.profile }}"
        capabilities: "{{ blocks.filter_capabilities.outputs.stdout | fromjson }}"
        permissions: "{{ inputs.permissions }}"

  # ===========================================================================
  # PHASE 2: GATHER - collect evidence (always runs)
  # ===========================================================================
  - id: gather
    type: Workflow
    description: Collect evidence based on pipeline_config.gather settings.
    depends_on: [categorize]
    condition: "{{ blocks.categorize.succeeded }}"
    inputs:
      workflow: cortex-phase-gather
      inputs:
        prompt: "{{ inputs.prompt }}"
        context:
          repo_path: "{{ inputs.context.repo_path | default('.') }}"
          category: "{{ blocks.categorize.outputs.result.category | default('understanding') }}"
        # Pipeline config from CATEGORIZE
        pipeline_config: "{{ blocks.categorize.outputs.pipeline_config | default({}) }}"
        depth: "{{ inputs.depth }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        state: "{{ blocks.categorize.outputs.state }}"
        parent_id: "{{ blocks.register.outputs.task.task_id }}"
        profile: "{{ inputs.profile }}"
        capabilities: "{{ blocks.filter_capabilities.outputs.stdout | fromjson }}"
        permissions: "{{ inputs.permissions }}"

  # ===========================================================================
  # PHASE 3: REASON - analyze + synthesize (always runs)
  # ===========================================================================
  - id: reason
    description: Analyze evidence and synthesize into unified conclusions.
    depends_on: [gather]
    condition: "{{ blocks.gather.succeeded }}"
    type: Workflow
    inputs:
      workflow: cortex-phase-reason
      inputs:
        prompt: "{{ inputs.prompt }}"
        context:
          repo_path: "{{ inputs.context.repo_path | default('.') }}"
          category: "{{ blocks.categorize.outputs.result.category | default('understanding') }}"
          gather_result: "{{ blocks.gather.outputs.result | default({}) }}"
        # Merge GATHER's config override into pipeline_config
        pipeline_config: |
          {{ blocks.categorize.outputs.pipeline_config | default({}) | combine(blocks.gather.outputs.config_override | default({}), recursive=True) }}
        depth: "{{ inputs.depth }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        state: "{{ blocks.gather.outputs.state }}"
        parent_id: "{{ blocks.register.outputs.task.task_id }}"
        profile: "{{ inputs.profile }}"
        capabilities: "{{ blocks.filter_capabilities.outputs.stdout | fromjson }}"
        permissions: "{{ inputs.permissions }}"

  # ===========================================================================
  # PHASE 4: ACT - take action (always runs, respects trigger policy)
  # ===========================================================================
  - id: act
    description: Take action based on synthesis and pipeline_config.act settings.
    depends_on: [reason]
    condition: "{{ blocks.reason.succeeded }}"
    type: Workflow
    inputs:
      workflow: cortex-phase-act
      inputs:
        prompt: "{{ inputs.prompt }}"
        context:
          repo_path: "{{ inputs.context.repo_path | default('.') }}"
          category: "{{ blocks.categorize.outputs.result.category | default('understanding') }}"
          synthesis: "{{ blocks.reason.outputs.synthesis | default({}) }}"
          original_prompt: "{{ inputs.context.original_prompt | default(inputs.prompt) }}"
        # Merge REASON's config override into pipeline_config
        pipeline_config: |
          {{ blocks.categorize.outputs.pipeline_config | default({}) | combine(blocks.gather.outputs.config_override | default({}), recursive=True) | combine(blocks.reason.outputs.config_override | default({}), recursive=True) }}
        depth: "{{ inputs.depth }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        state: "{{ blocks.reason.outputs.state }}"
        parent_id: "{{ blocks.register.outputs.task.task_id }}"
        profile: "{{ inputs.profile }}"
        capabilities: "{{ blocks.filter_capabilities.outputs.stdout | fromjson }}"
        permissions: "{{ inputs.permissions }}"

  # ===========================================================================
  # TRACK COMPLETION - store synthesis for child querying
  # ===========================================================================
  - id: track_done
    type: Workflow
    description: Mark cell complete and store synthesis for child querying.
    depends_on:
      - block: early_termination
        required: false
      - block: reason
        required: false
      - block: act
        required: false
    inputs:
      workflow: agent-state-management
      inputs:
        state: "{{ blocks.register.outputs.state }}"
        task_id: "{{ blocks.register.outputs.task.task_id }}"
        status: "done"
        caller: "cortex-cell"
        data:
          prompt: "{{ inputs.prompt }}"
          depth: "{{ inputs.depth }}"
          iterations: "{{ inputs.iterations }}"
          spawning_phase: "{{ inputs.context.spawning_phase | default('root') }}"
          # CRITICAL: Store response and synthesis so REASON phase can query children
          response: |
            {{ blocks.reason.outputs.response if blocks.reason.succeeded
               else (blocks.early_termination.outputs.stdout | fromjson).response if blocks.early_termination.succeeded
               else 'No response produced' }}
          synthesis: |
            {{ blocks.reason.outputs.synthesis if blocks.reason.succeeded
               else (blocks.early_termination.outputs.stdout | fromjson).synthesis if blocks.early_termination.succeeded
               else {} }}
          # Store action completion status for continuation
          complete: "{{ blocks.act.outputs.complete | default(true) }}"
          continuation_needed: "{{ blocks.act.outputs.continuation_needed | default(false) }}"

# =============================================================================
# OUTPUTS
# =============================================================================
outputs:
  synthesis:
    type: dict
    description: "Unified synthesis from the cognitive cycle."
    value: |
      {{ blocks.reason.outputs.synthesis if blocks.reason.succeeded
         else (blocks.early_termination.outputs.stdout | fromjson).synthesis if blocks.early_termination.succeeded
         else {'findings': [], 'summary': 'No synthesis'} }}

  response:
    type: str
    description: "Direct response to the query."
    value: |
      {{ blocks.reason.outputs.response if blocks.reason.succeeded
         else (blocks.early_termination.outputs.stdout | fromjson).response if blocks.early_termination.succeeded
         else 'No response produced' }}

  categorization:
    type: dict
    description: "Query categorization result with pipeline_config."
    value: "{{ blocks.categorize.outputs.result if blocks.categorize.succeeded else {} }}"

  pipeline_config:
    type: dict
    description: "Final pipeline configuration (with all overrides applied)."
    value: |
      {{ blocks.categorize.outputs.pipeline_config | default({}) | combine(blocks.gather.outputs.config_override | default({}), recursive=True) | combine(blocks.reason.outputs.config_override | default({}), recursive=True) if blocks.reason.succeeded else {} }}

  actions:
    type: dict
    description: "Action results (if any were taken)."
    value: "{{ blocks.act.outputs.result if blocks.act.succeeded else {} }}"

  complete:
    type: bool
    description: "Whether the task was fully completed."
    value: "{{ blocks.act.outputs.complete | default(true) }}"

  continuation_needed:
    type: bool
    description: "Whether a continuation cell should be spawned."
    value: "{{ blocks.act.outputs.continuation_needed | default(false) }}"

  continuation_prompt:
    type: str
    description: "Prompt for continuation cell if needed."
    value: "{{ blocks.act.outputs.continuation_prompt | default('') }}"

  task_id:
    type: str
    description: "This cell's task ID."
    value: "{{ blocks.register.outputs.task.task_id }}"

  state:
    type: str
    description: "Path to state database."
    value: "{{ blocks.register.outputs.state }}"
