name: cortex-phase-gather
description: |
  CORTEX Gather Phase (ReAct Pattern) - collects evidence with recursive spawning.

  Industry Standard: ReAct (Reason + Act) + Reflexion Hybrid
  - RECALL = THINK (query existing evidence + facts from DB)
  - PLAN   = REASON (LLM plans operations and investigations)
  - ACT    = dispatch + investigations (execute and store evidence)
  - Loop via recursion when investigations produce new knowledge

  Quality emerges from recursion - each level adds more evidence to shared DB.
  No explicit sufficiency check - REASON phase is the true gatekeeper.

tags: [cortex, phase, gather, react]

inputs:
  prompt:
    type: str
    description: The prompt to gather evidence for.
    required: true

  system:
    type: str
    description: System prompt override.
    default: |
      You are the evidence gathering module of a recursive cognitive system (CORTEX).
      Your role is to plan and execute data collection to answer queries.

      Be efficient - gather only what's needed based on the configured depth level.
      Store important files to memory for use by later phases.

      If you discover something that requires different analysis than expected,
      you can output config_override to adjust REASON/ACT behavior.

      Be honest about your confidence.
      Express ALL questions via investigations.

  context:
    type: dict
    description: Context including repo_path, category, etc.
    default: {}

  pipeline_config:
    type: dict
    description: Pipeline configuration from CATEGORIZE.
    default: {}

  synthesis:
    type: list
    description: Accumulated synthesis from previous investigations.
    default: []

  depth:
    type: num
    description: Current recursion depth.
    default: 0

  max_depth:
    type: num
    description: Maximum recursion depth.
    default: 5

  iterations:
    type: num
    description: Current task completion iteration.
    default: 0

  max_iterations:
    type: num
    description: Maximum continuation attempts.
    default: 3

  confidence_threshold:
    type: num
    description: Minimum confidence to skip investigation.
    default: 0.9

  state:
    type: str
    description: Path to SQLite state database.
    default: ""

  models:
    type: dict
    description: Model definitions for CRUD operations.
    default: {}

  parent_id:
    type: str
    description: Parent task ID for task tree.
    default: ""

  profile:
    type: str
    description: LLM profile to use.
    default: "default"

  capabilities:
    type: list
    description: Available capabilities registry (filtered by permissions).
    default: []

  permissions:
    type: dict
    description: Permission flags for capability filtering.
    default: { "read": true, "write": false, "execute": false }

blocks:
  # ===========================================================================
  # STEP 1: Register Phase Task (model-based insert with auto UUID)
  # ===========================================================================
  - id: register
    type: Sql
    description: Register this phase in the task tree.
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: insert
      data:
        parent_id: "{{ inputs.parent_id if inputs.parent_id else none }}"
        kind: phase
        name: gather
        metadata: "{{ {'labels': {'phase_order': 2, 'strategy': inputs.pipeline_config.gather.depth | default('focused')}} }}"
        inputs: "{{ inputs }}"
        status: running
        depth: "{{ inputs.depth }}"

  - id: build_schema
    type: Workflow
    description: Generate response schema with enforced capability enum.
    depends_on: [register]
    inputs:
      workflow: cortex-internal-schema-operations
      inputs:
        capabilities: "{{ inputs.capabilities }}"
        phase: "gather"
        include_spawn: true
        include_completion: false
        include_config_override: true

  - id: recall
    type: Sql
    description: THINK - Query existing evidence and facts from memory.
    depends_on: [register]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT namespace as evidence_type, key, value, metadata,
               json_extract(metadata, '$.byte_size') as byte_size
        FROM memory
        WHERE namespace IN ('content', 'outline', 'search')
        ORDER BY namespace, key
        LIMIT 200

  - id: plan
    type: LLMCall
    description: PLAN - Decide what evidence to gather based on query + existing knowledge.
    depends_on:
      - block: register
        required: true
      - block: build_schema
        required: true
      - block: recall
        required: false
    inputs:
      profile: "{{ inputs.profile }}"
      timeout: 600
      system_instructions: "{{ inputs.system }}"
      prompt: |
        # Evidence Gathering Planning (ReAct Pattern)

        ## Query
        {{ inputs.prompt }}

        ## Gather Depth: {{ get(inputs.pipeline_config, 'gather', {}).depth | default('focused') | upper }}

        {% if inputs.context %}
        ## Context
        {{ inputs.context | tojson }}
        {% endif %}

        {% if get(blocks.recall.outputs, 'rows', []) | length > 0 %}
        ## Evidence Already Gathered ({{ get(blocks.recall.outputs, 'rows', []) | length }} items)
        {% for item in get(blocks.recall.outputs, 'rows', []) %}
        - [{{ item.evidence_type }}] {{ item.key }}
        {% endfor %}
        {% endif %}

        {% if inputs.synthesis | length > 0 %}
        ## Previous Investigations (Reflexion)
        {% for c in inputs.synthesis %}
        ### Investigation {{ loop.index }}
        - Prompt: {{ c.prompt }}
        - Response: {{ c.response }}
        {% if c.synthesis %}
        - Key Findings: {{ c.synthesis.summary | default('N/A') }}
        {% endif %}
        {% endfor %}
        {% endif %}

        ## Depth-Specific Instructions

        {% if get(inputs.pipeline_config, 'gather', {}).depth == 'shallow' %}
        **SHALLOW DEPTH**: Minimal gathering for quick verification.
        - 1-2 targeted searches only
        - Focus on existence verification
        - Skip broad exploration
        {% elif get(inputs.pipeline_config, 'gather', {}).depth == 'focused' %}
        **FOCUSED DEPTH**: Targeted gathering in specific area.
        - 3-5 searches in relevant directories
        - Get key files, not everything
        - Follow obvious connections
        {% elif get(inputs.pipeline_config, 'gather', {}).depth == 'broad' %}
        **BROAD DEPTH**: Comprehensive search across codebase.
        - Multiple search patterns
        - Cover all relevant directories
        - Cast a wide net
        {% elif get(inputs.pipeline_config, 'gather', {}).depth == 'deep' %}
        **DEEP DEPTH**: Everything relevant + context.
        - Full file contents, not just outlines
        - Include related/dependent code
        - Get tests, configs, documentation
        {% else %}
        **DEFAULT**: Use focused gathering strategy.
        {% endif %}

        ## Available Capabilities (ATOMIC Operations)

        Use these capability workflows in your `operations` array:
        {% if inputs.capabilities | length > 0 %}
        {% for cap in inputs.capabilities %}
        **{{ cap.name }}** - {{ cap.description }}
        {% for key, schema in cap.inputs.items() %}
          - {{ key }} ({{ schema.type }}{% if schema.required %}, required{% endif %}): {{ schema.description }}
        {% endfor %}
        {% endfor %}
        {% else %}
        No capabilities available (check permissions).
        {% endif %}

        ## Operation Examples (REQUIRED FORMAT)

        **IMPORTANT**: Every operation MUST include the `inputs` object with capability-specific fields.

        ```json
        {
          "operations": [
            {
              "capability": "cortex-gather-files",
              "inputs": {"patterns": ["src/**/*.yaml", "*.md"]},
              "reason": "Read workflow definitions and documentation"
            },
            {
              "capability": "cortex-gather-search",
              "inputs": {"pattern": "def execute", "path": "src/", "file_type": "py"},
              "reason": "Find execute method implementations"
            }
          ]
        }
        ```

        ## Questions (Spawning Child Cells)

        **Questions = How you express uncertainty.** When you don't know something, ASK.

        | Confidence | Expected Action |
        |------------|-----------------|
        | 0.9 - 1.0  | Operations only (highly confident) |
        | 0.7 - 0.9  | Consider targeted questions |
        | 0.5 - 0.7  | **SHOULD** ask questions to clarify |
        | < 0.5      | **MUST** ask questions with specific prompts |

        **Example when uncertain:**
        ```json
        {
          "confidence": 0.5,
          "result": {
            "strategy": "Need more information",
            "operations": [],
            "questions": [
              {"prompt": "What authentication mechanism does this codebase use?",
               "reason": "Cannot find auth implementation in src/auth or src/security"}
            ]
          }
        }
        ```

        **Key rules:**
        1. If confidence < 0.7 and no useful operations, ASK questions
        2. Questions spawn SEPARATE cognitive cycles (child cells)
        3. Only ask DIFFERENT questions (not analysis of what you're already gathering)
        4. Do NOT guess - if uncertain, express it through questions

        **DO NOT ask:**
        - "Analyze the files I'm gathering" (REASON phase does this)
        - Restated versions of the parent prompt
        - Redundant or duplicate questions

        **DO ask:**
        - Questions about DIFFERENT sources ("What database schema exists?")
        - Questions about DIFFERENT domains ("How does frontend handle this?")

        Question policy: {{ get(inputs.pipeline_config, 'gather', {}).spawn | default('complex_only') }}
        Current depth: {{ inputs.depth }} / {{ inputs.max_depth }}

        **REMEMBER**: After gathering, REASON phase will analyze everything. Questions are for
        getting MORE information, not for analyzing what you already have.

        ## Config Override

        If you discover something unexpected that should change how REASON or ACT
        behaves, output config_override. For example:
        - Found security issues → reason.goal: evaluate, act.trigger: findings_require
        - Found complex architecture → reason.spawn: uncertain_only

      response_schema: "{{ blocks.build_schema.outputs.schema }}"

  # ===========================================================================
  # STEP 3b: Store LLM call for debugging
  # ===========================================================================
  - id: store_llm_call
    type: Sql
    description: Store LLM call details for debugging and analysis.
    depends_on:
      - block: plan
        required: false
    condition: "{{ inputs.state | trim != '' and blocks.plan.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.llm_call }}"
      op: insert
      data:
        task_id: "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"
        phase: gather
        system_instructions: "{{ inputs.system | default('') }}"
        prompt: "{{ inputs.prompt }}"
        response: "{{ blocks.plan.outputs.response }}"
        model: "{{ blocks.plan.outputs.metadata.model | default('unknown') }}"
        tokens_prompt: "{{ blocks.plan.outputs.metadata.usage.prompt_tokens | default(0) }}"
        tokens_completion: "{{ blocks.plan.outputs.metadata.usage.completion_tokens | default(0) }}"

  - id: dispatch
    type: Workflow
    description: ACT - Execute capability workflows in parallel via for_each.
    depends_on: [plan]
    condition: |
      {{ get(blocks.plan.outputs.response.result, 'operations', []) | length > 0 }}
    for_each: "{{ get(blocks.plan.outputs.response.result, 'operations', []) }}"
    for_each_mode: parallel
    max_parallel: 5
    continue_on_error: true
    inputs:
      workflow: "{{ each.value.capability }}"
      inputs:
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"
        task_id: "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"
        base_path: "{{ get(inputs.context, 'repo_path', '.') }}"
        patterns: "{{ get(each.value.inputs, 'patterns', []) }}"
        pattern: "{{ get(each.value.inputs, 'pattern', '') }}"
        query: "{{ get(each.value.inputs, 'query', '') }}"
        mode: "{{ get(each.value.inputs, 'mode', 'outline') }}"
        path: "{{ get(each.value.inputs, 'path', '') }}"

  - id: questions
    type: Workflow
    description: ACT - Spawn child cortex-cells to answer questions.
    depends_on: [dispatch]
    condition: |
      {{ get(blocks.plan.outputs.response.result, 'questions', []) | length > 0
         and get(inputs.pipeline_config.gather, 'spawn', 'complex_only') != 'never'
         and inputs.depth < inputs.max_depth }}
    for_each: "{{ get(blocks.plan.outputs.response.result, 'questions', []) }}"
    for_each_mode: parallel
    max_parallel: 3
    continue_on_error: true
    inputs:
      workflow: cortex-cell
      inputs:
        prompt: "{{ each.value.prompt }}"
        context: "{{ inputs.context | combine({'parent_prompt': inputs.prompt, 'spawn_reason': each.value.reason}) }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"

  - id: combine_results
    type: Shell
    description: Combine question prompts with their results for Reflexion.
    depends_on: [questions]
    condition: |
      {{ blocks.questions.succeeded
         and get(blocks.questions.metadata, 'count', 0) > 0 }}
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        # Question requests (what we asked)
        requests = json.loads(os.environ.get('REQUESTS', '[]'))
        # Question outputs (what we got back)
        outputs = json.loads(os.environ.get('OUTPUTS', '[]'))
        # Previous synthesis (accumulated)
        previous = json.loads(os.environ.get('PREVIOUS', '[]'))

        # Combine requests with outputs into Reflexion-compatible format
        combined = []
        for i, req in enumerate(requests):
            result = outputs[i] if i < len(outputs) else {}
            combined.append({
                'prompt': req.get('prompt', ''),
                'reason': req.get('reason', ''),
                'response': result.get('response', ''),
                'synthesis': result.get('synthesis', {})
            })

        # Merge with previous synthesis
        all_synthesis = previous + combined
        print(json.dumps(all_synthesis))
        EOF
      env:
        REQUESTS: "{{ get(blocks.plan.outputs.response.result, 'questions', []) | tojson }}"
        OUTPUTS: "{{ blocks.questions.outputs | default([]) | tojson }}"
        PREVIOUS: "{{ inputs.synthesis | tojson }}"

  - id: recurse
    type: Workflow
    description: LOOP - Recurse with accumulated syntheses from investigations.
    depends_on: [combine_results]
    condition: |
      {{ blocks.combine_results.succeeded
         and inputs.depth < inputs.max_depth }}
    inputs:
      workflow: cortex-phase-gather
      inputs:
        prompt: "{{ inputs.prompt }}"
        system: "{{ inputs.system }}"
        context: "{{ inputs.context }}"
        pipeline_config: "{{ inputs.pipeline_config }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"
        profile: "{{ inputs.profile }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"
        synthesis: "{{ blocks.combine_results.outputs.stdout | fromjson }}"

  # ===========================================================================
  # Track Completion (direct Sql UPDATE)
  # ===========================================================================
  - id: track_done
    type: Sql
    description: Mark phase complete and compile result.
    depends_on:
      - block: register
        required: true
      - block: dispatch
        required: false
      - block: questions
        required: false
      - block: combine_results
        required: false
      - block: recurse
        required: false
    condition: "{{ blocks.register.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        UPDATE tasks
        SET status = 'done',
            outputs = ?,
            updated_at = datetime('now')
        WHERE id = ?
      params:
        - >-
          {{ {
            'strategy': blocks.plan.outputs.response.result.strategy | default(''),
            'operations_executed': blocks.dispatch.metadata.count | default(0),
            'operations_failed': blocks.dispatch.metadata.count_failed | default(0),
            'questions_spawned': blocks.questions.metadata.count | default(0),
            'questions_failed': blocks.questions.metadata.count_failed | default(0),
            'confidence': blocks.plan.outputs.response.confidence | default(0),
            'depth': inputs.depth,
            'errors': blocks.dispatch.metadata.errors | default([])
          } | tojson }}
        - "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"

outputs:
  result:
    type: dict
    description: "Gathering result. Recursed result passes through unchanged."
    value: |
      {{ blocks.recurse.outputs.result if blocks.recurse.succeeded else {
        'strategy': blocks.plan.outputs.response.result.strategy | default(''),
        'operations_executed': blocks.dispatch.metadata.count | default(0),
        'operations_failed': blocks.dispatch.metadata.count_failed | default(0),
        'questions_spawned': blocks.questions.metadata.count | default(0),
        'questions_failed': blocks.questions.metadata.count_failed | default(0),
        'confidence': blocks.plan.outputs.response.confidence | default(0),
        'depth': inputs.depth
      } }}

  config_override:
    type: dict
    description: "Config override for REASON/ACT based on discoveries."
    value: |
      {{ blocks.recurse.outputs.config_override if blocks.recurse.succeeded
         else (blocks.plan.outputs.response.config_override | default({})) }}

  state:
    type: str
    description: "Path to state database."
    value: "{{ inputs.state }}"
