# =============================================================================
# CORTEX Gather Phase
# =============================================================================
#
# Enhancements:
#   - Directory tree discovery: Auto-scans repo structure BEFORE planning
#   - Tree stored in memory: Available to LLM for informed pattern generation
#   - RRF salience filtering for context budget
#   - BM25 keyword search for file ranking
#   - Semantic vector search for embedding-based similarity
#   - Context budget enforcement (default 60% of context window)
#   - Iteration support for DECIDE â†’ REFINE loop
#
# Execution Order:
#   1. Register phase
#   2. Discover tree structure (stores in memory.structure namespace)
#   3. Salience filtering (keyword + semantic + RRF fusion)
#   4. Recall existing evidence from memory
#   5. Plan LLM (now has tree context for smart pattern generation)
#   6. Dispatch capability operations
#   7. Handle questions/recursion
#
# =============================================================================

name: cortex-phase-gather
description: "CORTEX Gather Phase - collects evidence with RRF salience filtering and cell spawning"

tags: [cortex, phase, gather, salience]

inputs:
  prompt:
    type: str
    description: The prompt to gather evidence for.
    required: true

  system:
    type: str
    description: System prompt override.
    default: |
      You are the evidence gathering module of a recursive cognitive system (CORTEX).
      Your role is to plan and execute data collection to answer queries.

      Be efficient - gather only what's needed based on the configured depth level.
      Store important files to memory for use by later phases.

  context:
    type: dict
    description: Context including repo_path, category, etc.
    default: {}

  pipeline_config:
    type: dict
    description: Pipeline configuration from CATEGORIZE.
    default: {}

  synthesis:
    type: list
    description: Accumulated synthesis from previous investigations.
    default: []

  depth:
    type: num
    description: Current recursion depth.
    default: 0

  max_depth:
    type: num
    description: Maximum recursion depth.
    default: 5

  iterations:
    type: num
    description: Current task completion iteration.
    default: 0

  max_iterations:
    type: num
    description: Maximum continuation attempts.
    default: 3

  confidence_threshold:
    type: num
    description: Minimum confidence to skip investigation.
    default: 0.9

  state:
    type: str
    description: Path to SQLite state database.
    default: ""

  models:
    type: dict
    description: Model definitions for CRUD operations.
    default: {}

  parent_id:
    type: str
    description: Parent task ID for task tree.
    default: ""

  profile:
    type: str
    description: LLM profile to use.
    default: "default"

  capabilities:
    type: list
    description: Available capabilities registry.
    default: []

  permissions:
    type: dict
    description: Permission flags.
    default: { "read": true, "write": false, "execute": false }

  # v2 addition: evidence targets from DECIDE â†’ REFINE loop
  evidence_targets:
    type: list
    description: Specific evidence to gather (from DECIDE refine action).
    default: []

  # Embedding profile for semantic search
  embedding_profile:
    type: str
    description: LLM profile for embedding generation.
    default: "embedding"

  # addition: feature toggles
  features:
    type: dict
    description: feature toggles.
    default:
      salience_enabled: false
      semantic_enabled: true
      context_budget:
        max_tokens: 60000 # ~60% of 100k context window
        max_files: 50 # Maximum files to include

blocks:
  - id: register
    type: Sql
    description: Register this phase in the task tree.
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: insert
      data:
        parent_id: "{{ inputs.parent_id if inputs.parent_id else none }}"
        kind: phase
        name: gather
        metadata: "{'labels': {'phase_order': 2, 'strategy': {{ get(inputs.pipeline_config, 'gather.depth', 'focused') }}, 'version': 'v1'}}"
        inputs: "{{ inputs }}"
        status: running
        depth: "{{ inputs.depth }}"

  - id: discover_tree
    type: Workflow
    description: "Discover directory structure before planning."
    depends_on: [register]
    inputs:
      workflow: cortex-gather-tree
      inputs:
        base_path: "{{ inputs.context.repo_path | default('.') }}"
        max_depth: 4
        max_files: 500
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        task_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"

  - id: keyword_search
    type: Workflow
    description: "Salience: BM25 keyword search for file ranking."
    depends_on: [register, discover_tree]
    condition: "{{ inputs.features.salience_enabled | default(false) }}"
    inputs:
      workflow: cortex-keyword-search
      inputs:
        query: "{{ inputs.prompt }}"
        base_path: "{{ inputs.context.repo_path | default('.') }}"
        max_results: "{{ get(inputs.features, 'context_budget.max_files', 50) }}"
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        task_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"

  - id: semantic_search
    type: Workflow
    description: "Salience: Semantic vector search for embedding-based similarity."
    depends_on: [keyword_search]
    condition: "{{ inputs.features.salience_enabled | default(false) and inputs.features.semantic_enabled | default(true) and blocks.keyword_search.succeeded }}"
    inputs:
      workflow: cortex-semantic-search
      inputs:
        query: "{{ inputs.prompt }}"
        files: "{{ blocks.keyword_search.outputs.ranked_files | map(attribute='path') | list }}"
        profile: "{{ inputs.embedding_profile }}"
        max_results: "{{ get(inputs.features, 'context_budget.max_files', 50) }}"
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"

  - id: rrf_fusion
    type: Workflow
    description: "Salience: RRF fusion to combine keyword and semantic rankings."
    depends_on:
      - block: keyword_search
        required: true
      - block: semantic_search
        required: false
    condition: "{{ blocks.keyword_search.succeeded }}"
    inputs:
      workflow: cortex-rrf-fusion
      inputs:
        rankings: >-
          {{
            [
              {'source': 'keyword', 'weight': 1.0, 'files': blocks.keyword_search.outputs.ranked_files | default([])},
              {'source': 'semantic', 'weight': 1.0, 'files': blocks.semantic_search.outputs.rankings | default([])}
            ] if blocks.semantic_search.succeeded
            else [
              {'source': 'keyword', 'weight': 1.0, 'files': blocks.keyword_search.outputs.ranked_files | default([])}
            ]
          }}
        k: 60
        context_budget: "{{ get(inputs.features, 'context_budget.max_tokens', 60000) }}"
        max_results: "{{ get(inputs.features, 'context_budget.max_files', 50) }}"
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        task_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"

  - id: build_schema
    type: Workflow
    description: Generate response schema with enforced capability enum.
    depends_on: [register]
    inputs:
      workflow: cortex-internal-schema-operations
      inputs:
        capabilities: "{{ inputs.capabilities }}"
        phase: "gather"
        include_spawn: true
        include_completion: false
        include_config_override: true

  - id: recall
    type: Sql
    description: Query existing evidence from memory (includes structure from tree discovery).
    depends_on: [register, discover_tree]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT namespace as evidence_type, key, value, metadata,
               json_extract(metadata, '$.byte_size') as byte_size
        FROM memory
        WHERE namespace IN ('content', 'outline', 'search', 'structure')
        ORDER BY namespace, key
        LIMIT 200

  - id: plan
    type: LLMCall
    description: Decide what evidence to gather.
    depends_on:
      - block: register
        required: true
      - block: build_schema
        required: true
      - block: recall
        required: false
      - block: discover_tree
        required: false
      - block: keyword_search
        required: false
      - block: semantic_search
        required: false
      - block: rrf_fusion
        required: false
    inputs:
      profile: "{{ inputs.profile }}"
      timeout: 600
      system_instructions: "{{ inputs.system }}"
      prompt: |
        # Evidence Gathering (CORTEX)

        ## Query
        {{ inputs.prompt }}

        ## Gather Depth: {{ get(inputs.pipeline_config, 'gather.depth', 'focused') | upper }}

        {% if blocks.discover_tree.succeeded %}
        ## ğŸ“ Directory Structure ({{ blocks.discover_tree.outputs.file_count }} files, {{ blocks.discover_tree.outputs.dir_count }} dirs)

        **Use this to generate precise glob patterns. These files actually exist.**

        Type breakdown: {{ blocks.discover_tree.outputs.type_summary }}

        ```
        {{ blocks.discover_tree.outputs.tree_text | truncate(3000) }}
        ```
        {% if blocks.discover_tree.outputs.truncated %}
        *(Tree truncated - {{ blocks.discover_tree.outputs.file_count }} total files)*
        {% endif %}

        {% endif %}

        {% if inputs.evidence_targets | length > 0 %}
        ## Specific Evidence Targets (from DECIDE refine)
        These are specific pieces of evidence that were requested:
        {% for target in inputs.evidence_targets %}
        - {{ target }}
        {% endfor %}
        **Focus on gathering these specific items.**
        {% endif %}

        {% if inputs.context %}
        ## Context
        {{ inputs.context | tojson }}
        {% endif %}

        {% if blocks.rrf_fusion.succeeded %}
        ## Salience Prioritized Files (RRF ranked)
        These files have been ranked by relevance to your query. Prioritize reading these:

        **Context Budget**: {{ blocks.rrf_fusion.outputs.tokens_used | default(0) }} / {{ inputs.features.context_budget.max_tokens | default(60000) }} tokens

        {% for file in blocks.rrf_fusion.outputs.fused_ranking[:20] %}
        {{ loop.index }}. `{{ file.path }}` (RRF: {{ file.rrf_score }}, sources: {{ file.sources | join(', ') }})
        {% endfor %}
        {% if blocks.rrf_fusion.outputs.count > 20 %}
        ... and {{ blocks.rrf_fusion.outputs.count - 20 }} more files
        {% endif %}

        **IMPORTANT**: Focus on these prioritized files. They have been ranked by relevance using {{ 'BM25 keyword matching + semantic embeddings (RRF fusion)' if blocks.semantic_search.succeeded else 'BM25 keyword matching' }}.
        {% elif blocks.keyword_search.succeeded %}
        ## Keyword-Matched Files (BM25 ranked)
        {% for file in blocks.keyword_search.outputs.ranked_files[:15] %}
        {{ loop.index }}. `{{ file.path }}` (BM25: {{ file.bm25_score }}, terms: {{ file.terms_matched }})
        {% endfor %}
        {% endif %}

        {% if get(blocks.recall.outputs, 'rows', []) | length > 0 %}
        ## Evidence Already Gathered ({{ get(blocks.recall.outputs, 'rows', []) | length }} items)
        {% for item in get(blocks.recall.outputs, 'rows', []) %}
        - [{{ item.evidence_type }}] {{ item.key }}
        {% endfor %}
        {% endif %}

        {% if inputs.synthesis | length > 0 %}
        ## Previous Investigations
        {% for c in inputs.synthesis %}
        ### Investigation {{ loop.index }}
        - Prompt: {{ c.prompt }}
        - Response: {{ c.response }}
        {% endfor %}
        {% endif %}

        ## Depth Instructions

        {% if get(inputs.pipeline_config, 'gather.depth', '') == 'shallow' %}
        **SHALLOW**: 1-2 targeted searches, existence verification only
        {% elif get(inputs.pipeline_config, 'gather.depth', 'focused') == 'focused' %}
        **FOCUSED**: 3-5 searches in relevant directories, key files only
        {% elif get(inputs.pipeline_config, 'gather.depth', '') == 'broad' %}
        **BROAD**: Multiple search patterns, cover all relevant directories
        {% elif get(inputs.pipeline_config, 'gather.depth', '') == 'deep' %}
        **DEEP**: Full file contents, related code, tests, configs, docs
        {% endif %}

        ## Available Capabilities

        {% if inputs.capabilities | length > 0 %}
        {% for cap in inputs.capabilities %}
        **{{ cap.name }}** - {{ cap.description }}
        {% for key, schema in cap.inputs.items() %}
          - {{ key }} ({{ schema.type }}{% if schema.required %}, required{% endif %}): {{ schema.description }}
        {% endfor %}
        {% endfor %}
        {% else %}
        No capabilities available.
        {% endif %}

        ## Output

        Provide operations to gather evidence and questions for uncertainty.

      response_schema: "{{ blocks.build_schema.outputs.schema }}"

  - id: store_llm_call
    type: Sql
    description: Store LLM call details.
    depends_on:
      - block: plan
        required: false
    condition: "{{ inputs.state | trim != '' and blocks.plan.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.llm_call }}"
      op: insert
      data:
        task_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        phase: gather
        system_instructions: "{{ inputs.system | default('') }}"
        prompt: "{{ inputs.prompt }}"
        response: "{{ blocks.plan.outputs.response }}"
        model: "{{ get(blocks.plan.outputs.metadata, 'model', 'unknown') }}"
        prompt_tokens: "{{ get(blocks.plan.outputs, 'metadata.usage.prompt_tokens', 0) }}"
        completion_tokens: "{{ get(blocks.plan.outputs, 'metadata.usage.completion_tokens', 0) }}"
        duration_ms: "{{ get(blocks.plan.metadata, 'duration_ms', 0) }}"

  - id: dispatch
    type: Workflow
    description: Execute capability workflows in parallel.
    depends_on: [plan]
    condition: |
      {{ get(blocks.plan.outputs.response.result, 'operations', []) | length > 0 }}
    for_each: "{{ get(blocks.plan.outputs.response.result, 'operations', []) }}"
    for_each_mode: parallel
    max_parallel: 5
    continue_on_error: true
    inputs:
      workflow: "{{ each.value.capability }}"
      inputs:
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        task_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        base_path: "{{ get(inputs.context, 'repo_path', '.') }}"
        patterns: "{{ get(each.value.inputs, 'patterns', []) }}"
        pattern: "{{ get(each.value.inputs, 'pattern', '') }}"
        query: "{{ get(each.value.inputs, 'query', '') }}"
        mode: "{{ get(each.value.inputs, 'mode', 'outline') }}"
        path: "{{ get(each.value.inputs, 'path', '') }}"

  - id: questions
    type: Workflow
    description: Spawn child cortex-cell to answer questions.
    depends_on: [dispatch]
    condition: |
      {{ get(blocks.plan.outputs.response.result, 'questions', []) | length > 0
         and get(inputs.pipeline_config, 'gather.spawn', 'complex_only') != 'never'
         and inputs.depth < inputs.max_depth }}
    for_each: "{{ get(blocks.plan.outputs.response.result, 'questions', []) }}"
    for_each_mode: parallel
    max_parallel: 3
    continue_on_error: true
    inputs:
      workflow: cortex-cell
      inputs:
        prompt: "{{ each.value.prompt }}"
        context: "{{ inputs.context | combine({'parent_prompt': inputs.prompt, 'spawn_reason': each.value.reason}) }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"

  - id: combine_results
    type: Shell
    description: Combine question results for recursion.
    depends_on: [questions]
    condition: |
      {{ blocks.questions.succeeded
         and get(blocks.questions.metadata, 'count', 0) > 0 }}
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        requests = json.loads(os.environ.get('REQUESTS', '[]'))
        outputs = json.loads(os.environ.get('OUTPUTS', '[]'))
        previous = json.loads(os.environ.get('PREVIOUS', '[]'))

        combined = []
        for i, req in enumerate(requests):
            result = outputs[i] if i < len(outputs) else {}
            combined.append({
                'prompt': req.get('prompt', ''),
                'reason': req.get('reason', ''),
                'response': result.get('response', ''),
                'synthesis': result.get('synthesis', {})
            })

        all_synthesis = previous + combined
        print(json.dumps(all_synthesis))
        EOF
      env:
        REQUESTS: "{{ get(blocks.plan.outputs.response.result, 'questions', []) | tojson }}"
        OUTPUTS: "{{ blocks.questions.outputs | default([]) | tojson }}"
        PREVIOUS: "{{ inputs.synthesis | tojson }}"

  - id: recurse
    type: Workflow
    description: Recurse with accumulated syntheses.
    depends_on: [combine_results]
    condition: |
      {{ blocks.combine_results.succeeded
         and inputs.depth < inputs.max_depth }}
    inputs:
      workflow: cortex-phase-gather
      inputs:
        prompt: "{{ inputs.prompt }}"
        system: "{{ inputs.system }}"
        context: "{{ inputs.context }}"
        pipeline_config: "{{ inputs.pipeline_config }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ get(blocks.register.outputs, 'rows.0.id', '') }}"
        profile: "{{ inputs.profile }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"
        synthesis: "{{ blocks.combine_results.outputs.stdout }}"
        features: "{{ inputs.features }}"

  - id: track_done
    type: Sql
    description: Mark phase complete.
    depends_on:
      - block: register
        required: true
      - block: discover_tree
        required: false
      - block: dispatch
        required: false
      - block: questions
        required: false
      - block: combine_results
        required: false
      - block: recurse
        required: false
      - block: keyword_search
        required: false
      - block: semantic_search
        required: false
      - block: rrf_fusion
        required: false
    condition: "{{ blocks.register.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: update
      where:
        id: "{{ (blocks.register.outputs.rows | default([{}]))[0].id | default('') }}"
      data:
        status: done
        outputs: |
          {
            'strategy': {{ blocks.plan.outputs.response.result.strategy | default('') }},
            'operations_executed': {{ blocks.dispatch.metadata.count | default(0) }},
            'operations_failed': {{ blocks.dispatch.metadata.count_failed | default(0) }},
            'questions_spawned': {{ blocks.questions.metadata.count | default(0) }},
            'confidence': {{ blocks.plan.outputs.response.confidence | default(0) }},
            'depth': {{ inputs.depth }},
            'tree_discovered': {{ blocks.discover_tree.succeeded | default(false) }},
            'tree_file_count': {{ blocks.discover_tree.outputs.file_count | default(0) if blocks.discover_tree.succeeded else 0 }},
            'tree_dir_count': {{ blocks.discover_tree.outputs.dir_count | default(0) if blocks.discover_tree.succeeded else 0 }},
            'salience_enabled': {{ inputs.features.salience_enabled | default(false) }},
            'files_ranked': {{ blocks.rrf_fusion.outputs.count | default(0) if blocks.rrf_fusion.succeeded else (blocks.keyword_search.outputs.count | default(0) if blocks.keyword_search.succeeded else 0) }},
            'context_tokens_used': {{ blocks.rrf_fusion.outputs.tokens_used | default(0) if blocks.rrf_fusion.succeeded else 0 }}
          }"

outputs:
  result:
    type: dict
    description: "Gathering result."
    value: |-
      {%- if blocks.recurse.succeeded -%}
      {{ blocks.recurse.outputs.result }}
      {%- else -%}
      {
        'strategy': blocks.plan.outputs.response.result.strategy | default(''),
        'operations_executed': blocks.dispatch.metadata.count | default(0),
        'questions_spawned': blocks.questions.metadata.count | default(0),
        'confidence': blocks.plan.outputs.response.confidence | default(0),
        'depth': inputs.depth
      }
      {%- endif %}

  config_override:
    type: dict
    description: "Config override for downstream phases."
    value: |-
      {%- if blocks.recurse.succeeded -%}
      {{ blocks.recurse.outputs.config_override }}
      {%- else -%}
      {{ get(blocks.plan.outputs.response, 'config_override', {}) }}
      {%- endif -%}

  salience:
    type: dict
    description: "Salience filtering results."
    value: |-
      {%- if blocks.recurse.succeeded -%}
      {{ blocks.recurse.outputs.salience }}
      {%- else -%}
      {#- Pre-compute source block (RRF takes precedence over keyword search) -#}
      {%- set rrf = blocks.rrf_fusion -%}
      {%- set kw = blocks.keyword_search -%}
      {%- set sem = blocks.semantic_search -%}

      {#- Determine which source provides the ranking data -#}
      {%- set has_rrf = rrf.succeeded -%}
      {%- set has_kw = kw.succeeded -%}
      {%- set has_sem = sem.succeeded | default(false) -%}

      {#- Extract values from the best available source -#}
      {%- if has_rrf -%}
        {%- set files_ranked = rrf.outputs.count -%}
        {%- set files_excluded = rrf.outputs.excluded | length -%}
        {%- set tokens_used = rrf.outputs.tokens_used -%}
        {%- set tokens_remaining = rrf.outputs.tokens_remaining -%}
      {%- elif has_kw -%}
        {%- set files_ranked = kw.outputs.count -%}
        {%- set files_excluded = kw.outputs.excluded | length -%}
        {%- set tokens_used = kw.outputs.tokens_used -%}
        {%- set tokens_remaining = kw.outputs.tokens_remaining -%}
      {%- else -%}
        {%- set files_ranked = 0 -%}
        {%- set files_excluded = 0 -%}
        {%- set tokens_used = 0 -%}
        {%- set tokens_remaining = 0 -%}
      {%- endif -%}

      {#- Build the output dictionary -#}
      {
        'enabled': {{ get(inputs.features, 'salience_enabled', false) }},
        'semantic_enabled': {{ get(inputs.features, 'semantic_enabled', true) }},
        'semantic_used': {{ has_sem }},
        'files_ranked': {{ files_ranked }},
        'files_excluded': {{ files_excluded }},
        'tokens_used': {{ tokens_used }},
        'tokens_remaining': {{ tokens_remaining }},
        'keywords': {{ kw.outputs.keywords if has_kw else [] }},
        'sources_fused': {{ rrf.outputs.sources_fused if has_rrf else [] }}
      }
      {%- endif -%}

  prioritized_files:
    type: list
    description: "Top prioritized files from salience filtering."
    value: "{{ blocks.rrf_fusion.outputs.fused_ranking if blocks.rrf_fusion.succeeded else (blocks.keyword_search.outputs.ranked_files if blocks.keyword_search.succeeded else []) }}"

  tree:
    type: dict
    description: "Directory tree discovery results."
    value: |-
      {%- if blocks.discover_tree.succeeded -%}
      {
        'discovered': blocks.discover_tree.succeeded | default(false),
        'file_count': blocks.discover_tree.outputs.file_count | default(0),
        'dir_count': blocks.discover_tree.outputs.dir_count | default(0),
        'type_summary': blocks.discover_tree.outputs.type_summary | default(''),
        'truncated': blocks.discover_tree.outputs.truncated | default(false)
      }
      {%- else -%}
      {'discovered': false}
      {%- endif -%}

  tree_files:
    type: list
    description: "List of discovered files with metadata."
    value: "{{ get(blocks.discover_tree.outputs, 'files', []) }}"

  state:
    type: str
    description: "Path to state database."
    value: "{{ inputs.state }}"
