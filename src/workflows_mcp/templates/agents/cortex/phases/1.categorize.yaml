# CORTEX Categorize Phase
#
# Enhanced with predictive coding:
#   - execute: { enabled: bool, type: str } - Pre-reasoning command execution
#   - decide: { verify_required: bool } - Verification requirements
#   - verify: { enabled: bool, max_retries: int } - Verification loop settings
#   - Expectation formation for surprisal tracking

name: cortex-phase-categorize
description: "CORTEX Categorize Phase - classifies prompt with expectation formation"

tags: [cortex, phase, categorize, predictive-coding]

inputs:
  prompt:
    type: str
    description: The prompt to categorize.
    required: true

  system:
    type: str
    description: System prompt override.
    default: |
      You are the categorization module of a recursive cognitive system (CORTEX).
      Your role is to classify prompts to determine the optimal processing strategy.

      ## Critical Mindset
      Before committing to high confidence, ask yourself:
      - "Do I actually have evidence for this classification?"
      - If the query mentions specific files, code, or implementation details - you likely need investigation
      - Express uncertainty generously - it's better to investigate than to guess

      ## When to Express Uncertainty
      - References to specific code, files, or implementation details
      - Questions about "how" something works internally
      - Any technical claims that require reading actual code
      - Planning or architectural questions

      Be honest about your confidence.

  context:
    type: dict
    description: Shared context.
    default: {}

  memory:
    type: list
    description: List of memory keys to retrieve.
    default: []

  synthesis:
    type: list
    description: Accumulated synthesis from previous investigations.
    default: []

  depth:
    type: num
    description: Current recursion depth.
    default: 0

  max_depth:
    type: num
    description: Maximum recursion depth.
    default: 5

  confidence_threshold:
    type: num
    description: Minimum confidence to skip investigation.
    default: 0.9

  state:
    type: str
    description: Path to SQLite state database.
    default: ""
    required: true

  models:
    type: dict
    description: Model definitions for CRUD operations.
    default: {}
    required: true

  parent_id:
    type: str
    description: Parent task ID for task tree.
    default: ""

  profile:
    type: str
    description: LLM profile to use.
    default: "default"

  capabilities:
    type: list
    description: Available capabilities registry.
    default: []

  permissions:
    type: dict
    description: Permission flags.
    default: { "read": true, "write": false, "execute": false }

  iterations:
    type: num
    description: Current iteration count.
    default: 0

  max_iterations:
    type: num
    description: Maximum iterations.
    default: 3

  features:
    type: dict
    description: Feature toggles.
    default:
      expectations_enabled: false
      heuristics_enabled: false
      dual_track_enabled: false
      homeostatic_enabled: false
      g_score_thresholds:
        system1_max: 10
        system2_max: 50
        confirm_above: 50

  # Caution level from homeostatic control
  caution_level:
    type: num
    description: |
      Current caution level from homeostatic PID controller.
      Values: 0.5 (relaxed) to 2.0 (paranoid)
      Affects G-Score thresholds: adjusted_threshold = base_threshold / caution_level
    default: 1.0

blocks:
  - id: register_phase
    type: Sql
    description: Register this phase in the task tree.
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: insert
      data:
        parent_id: "{{ inputs.parent_id if inputs.parent_id else none }}"
        kind: phase
        name: categorize
        metadata: "{'labels': {'phase_order': 1, 'version': 'v1'}}"
        inputs: "{'prompt': {{ inputs.prompt }} }"
        status: running
        depth: "{{ inputs.depth }}"

  - id: query_heuristics
    type: Workflow
    description: "Query learned heuristics to inform categorization."
    depends_on: [register_phase]
    condition: "{{ inputs.features.heuristics_enabled | default(false) }}"
    inputs:
      workflow: cortex-query-heuristics
      inputs:
        query: "{{ inputs.prompt }}"
        category: "" # Query across all categories initially
        min_confidence: "{{ inputs.features.heuristics.min_confidence | default(0.7) }}"
        min_applications: "{{ inputs.features.heuristics.min_applications | default(3) }}"
        max_results: "{{ inputs.features.heuristics.max_results | default(5) }}"
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"
        task_id: "{{ inputs.parent_id }}"

  - id: retrieve_memory
    type: Sql
    description: Get files from memory by namespace.
    depends_on:
      - block: register_phase
        required: true
      - block: query_heuristics
        required: false
    condition: "{{ inputs.memory | length > 0 }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.memory }}"
      op: select
      where:
        namespace: content
      order:
        - key
      columns:
        - key
        - value
        - metadata

  - id: attempt
    type: LLMCall
    description: Classify the prompt.
    depends_on:
      - block: register_phase
        required: true
      - block: retrieve_memory
        required: false
      - block: query_heuristics
        required: false
    inputs:
      profile: "{{ inputs.profile }}"
      timeout: 600
      system_instructions: "{{ inputs.system }}"
      prompt: |
        # Prompt Categorization

        ## Prompt
        {{ inputs.prompt }}

        {% if inputs.context %}
        ## Context
        {{ inputs.context | tojson }}
        {% endif %}

        {% if blocks.query_heuristics.succeeded and blocks.query_heuristics.outputs.has_results %}
        ## Learned Heuristics
        These are patterns learned from previous similar tasks. Consider them when making your decision:
        {% for h in blocks.query_heuristics.outputs.heuristics[:5] %}
        {{ loop.index }}. **{{ h.rule }}**
           - Confidence: {{ (h.effective_confidence * 100) | round }}%
           - Success rate: {{ (h.success_rate * 100) | round }}% ({{ h.times_succeeded }}/{{ h.times_applied }} applications)
        {% endfor %}
        {% endif %}

        {% if blocks.retrieve_memory.succeeded and blocks.retrieve_memory.outputs.rows %}
        ## Retrieved Files
        {% for file in blocks.retrieve_memory.outputs.rows %}
        ### {{ file.key }}
        ```
        {{ file.value }}
        ```
        {% endfor %}
        {% endif %}

        {% if inputs.synthesis | length > 0 %}
        ## Previous Investigations
        {% for c in inputs.synthesis %}
        ### Investigation {{ loop.index }}
        - Question: {{ c.prompt }}
        - Answer: {{ c.response }}
        {% if c.synthesis %}
        - Key Findings: {{ c.synthesis.summary | default('N/A') }}
        {% endif %}
        {% endfor %}
        {% endif %}

        ## Categories

        Classify into ONE category:

        | Category | Description | Runs Tests/Commands? | Examples |
        |----------|-------------|---------------------|----------|
        | existence | Check if something exists | No | "Does file X exist?" |
        | understanding | Learn about something | No | "What does X do?" |
        | discovery | Find all instances | No | "Find all API endpoints" |
        | quality | Evaluate something | **YES** (lint+test) | "Is this code good?" |
        | planning | Create a plan | No | "How do I implement X?" |
        | debugging | Find root cause | **YES** (run to reproduce) | "Why does X fail?" |
        | action | Execute something | **YES** (then verify) | "Fix the bug", "Run tests" |

        **Categories marked YES will run commands BEFORE reasoning (CORTEX v2 feature).**

        ## Assessment

        Determine:
        1. **category**: Which category best fits this query?
        2. **confidence**: How confident are you? (0.0-1.0)
        3. **uncertainty**: If any uncertainty exists, describe what would help
        4. **impact_scope**: Estimate the scope of files/components affected:
           - "none" (0 files): Just reading/understanding
           - "single" (1-5 files): Single file or small change
           - "moderate" (6-20 files): Multiple related files
           - "large" (20+ files): Many files across codebase
           - "system-wide": Architecture or fundamental changes

      response_schema:
        type: object
        properties:
          result:
            type: object
            properties:
              category:
                type: string
                enum:
                  [
                    existence,
                    understanding,
                    discovery,
                    quality,
                    planning,
                    debugging,
                    action,
                  ]
              reasoning:
                type: string
              impact_scope:
                type: string
                enum: [none, single, moderate, large, system-wide]
                description: Estimated scope of files/components affected
            required: [category, reasoning, impact_scope]
          confidence:
            type: number
            minimum: 0
            maximum: 1
          uncertainty:
            type: object
            properties:
              exists:
                type: boolean
              question:
                type: string
            required: [exists]
        required: [result, confidence, uncertainty]

  - id: store_llm_call
    type: Sql
    description: Store LLM call details.
    depends_on: [attempt]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.llm_call }}"
      op: insert
      data:
        task_id: "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"
        phase: categorize
        system_instructions: "{{ inputs.system | default('') }}"
        prompt: "{{ inputs.prompt }}"
        response: "{{ blocks.attempt.outputs.response }}"
        model: "{{ blocks.attempt.outputs.metadata.model | default('unknown') }}"
        prompt_tokens: "{{ blocks.attempt.outputs.metadata.usage.prompt_tokens | default(0) }}"
        completion_tokens: "{{ blocks.attempt.outputs.metadata.usage.completion_tokens | default(0) }}"
        duration_ms: "{{ get(blocks.attempt.metadata, 'duration_ms', 0) }}"

  - id: form_expectation
    type: Shell
    description: Generate expectation based on category (predicts what will happen).
    depends_on: [attempt, lookup_config]
    condition: "{{ inputs.features.expectations_enabled | default(false) and blocks.attempt.succeeded }}"
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os
        import hashlib

        category = os.environ.get('CATEGORY', 'understanding')
        confidence = float(os.environ.get('CONFIDENCE', '0.5'))
        prompt = os.environ.get('PROMPT', '')
        pipeline_config_json = os.environ.get('PIPELINE_CONFIG', '{}')

        try:
            pipeline_config = json.loads(pipeline_config_json)
        except:
            pipeline_config = {}

        OUTCOME_PREDICTIONS = {
            "existence": {
                "outcome": "verified",
                "description": "Existence check will confirm or deny",
                "probability_base": 0.85
            },
            "understanding": {
                "outcome": "explained",
                "description": "Concept will be explained without issues",
                "probability_base": 0.80
            },
            "discovery": {
                "outcome": "enumerated",
                "description": "Items will be found and listed",
                "probability_base": 0.75
            },
            "quality": {
                "outcome": "issues_found" if pipeline_config.get('execute', {}).get('enabled') else "assessed",
                "description": "Quality issues may be detected via tests/lint",
                "probability_base": 0.70
            },
            "planning": {
                "outcome": "planned",
                "description": "Plan will be created successfully",
                "probability_base": 0.85
            },
            "debugging": {
                "outcome": "diagnosed",
                "description": "Root cause will be identified",
                "probability_base": 0.60  # Debugging is harder
            },
            "action": {
                "outcome": "executed",
                "description": "Action will complete with verification",
                "probability_base": 0.65  # Actions can fail
            }
        }

        prediction_template = OUTCOME_PREDICTIONS.get(category, OUTCOME_PREDICTIONS['understanding'])

        # Adjust probability based on categorization confidence
        # Higher confidence in category → higher confidence in prediction
        adjusted_probability = prediction_template['probability_base'] * (0.5 + 0.5 * confidence)
        adjusted_probability = min(0.95, max(0.1, adjusted_probability))

        # Generate context hash for clustering similar situations
        context_hash = hashlib.sha256(f"{category}:{prompt[:100]}".encode()).hexdigest()[:16]

        expectation = {
            'prediction': {
                'outcome': prediction_template['outcome'],
                'probability': round(adjusted_probability, 3),
                'factors': {
                    'category': category,
                    'category_confidence': confidence,
                    'execute_enabled': pipeline_config.get('execute', {}).get('enabled', False),
                    'verify_required': pipeline_config.get('decide', {}).get('verify_required', False)
                }
            },
            'basis': prediction_template['description'],
            'context_hash': context_hash
        }

        print(json.dumps(expectation))
        EOF
      env:
        CATEGORY: "{{ blocks.attempt.outputs.response.result.category }}"
        CONFIDENCE: "{{ blocks.attempt.outputs.response.confidence }}"
        PROMPT: "{{ inputs.prompt }}"
        PIPELINE_CONFIG: "{{ get(blocks.lookup_config.outputs.stdout, 'pipeline_config', {}) | tojson }}"

  - id: store_expectation
    type: Sql
    description: Store the expectation in database.
    depends_on: [form_expectation]
    condition: "{{ blocks.form_expectation.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.expectation }}"
      op: insert
      data:
        task_id: "{{ inputs.parent_id }}"
        phase: categorize
        prediction: "{{ get(blocks.form_expectation.outputs.stdout, 'prediction', '') }}"
        basis: "{{ get(blocks.form_expectation.outputs.stdout, 'basis', '') }}"

  # STEP 6: Calculate G-Score for Dual-Track Routing
  # G-Score = Impact × Uncertainty
  #
  # Impact factors (based on scope):
  #   - none (0 files): 1
  #   - single (1-5 files): 3
  #   - moderate (6-20 files): 5
  #   - large (20+ files): 8
  #   - system-wide: 10
  #
  # Uncertainty factors (based on confidence):
  #   - 0.9+: 1 (very confident)
  #   - 0.7-0.9: 3 (confident)
  #   - 0.5-0.7: 5 (uncertain)
  #   - 0.3-0.5: 7 (very uncertain)
  #   - <0.3: 9 (no idea)
  #
  # Routing thresholds (adjusted by caution_level):
  #   Base thresholds:
  #     - G-Score ≤ 10: System 1 (fast path)
  #     - G-Score > 10: System 2 (full loop)
  #     - G-Score > 50: Require user confirmation
  #
  #   Caution adjustment: adjusted_threshold = base_threshold / caution_level
  #     - Caution 0.5: thresholds × 2 (relaxed, e.g., 10 → 20)
  #     - Caution 1.0: thresholds × 1 (normal, e.g., 10)
  #     - Caution 1.5: thresholds / 1.5 (cautious, e.g., 10 → 7)
  #     - Caution 2.0: thresholds / 2 (paranoid, e.g., 10 → 5)
  - id: compute_g_score
    type: Shell
    description: Calculate G-Score for dual-track routing with caution adjustment.
    depends_on: [attempt, lookup_config]
    condition: "{{ inputs.features.dual_track_enabled | default(false) and blocks.attempt.succeeded }}"
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        impact_scope = os.environ.get('IMPACT_SCOPE', 'moderate')
        confidence = float(os.environ.get('CONFIDENCE', '0.5'))
        category = os.environ.get('CATEGORY', 'understanding')
        thresholds_json = os.environ.get('THRESHOLDS', '{}')
        caution_level = float(os.environ.get('CAUTION_LEVEL', '1.0'))
        homeostatic_enabled = os.environ.get('HOMEOSTATIC_ENABLED', 'false').lower() == 'true'

        try:
            thresholds = json.loads(thresholds_json)
        except:
            thresholds = {}

        # Base thresholds
        base_system1_max = thresholds.get('system1_max', 10)
        base_confirm_above = thresholds.get('confirm_above', 50)

        # CAUTION-ADJUSTED THRESHOLDS (Homeostatic Control)
        # Formula: adjusted_threshold = base_threshold / caution_level
        # Higher caution → lower thresholds → more conservative routing
        # Lower caution → higher thresholds → more aggressive routing
        if homeostatic_enabled and caution_level > 0:
            system1_max = int(base_system1_max / caution_level)
            confirm_above = int(base_confirm_above / caution_level)
            # Ensure minimum thresholds
            system1_max = max(3, system1_max)
            confirm_above = max(15, confirm_above)
        else:
            system1_max = base_system1_max
            confirm_above = base_confirm_above

        # IMPACT SCORE MAPPING
        IMPACT_SCORES = {
            'none': 1,       # Just reading/understanding
            'single': 3,     # 1-5 files
            'moderate': 5,   # 6-20 files
            'large': 8,      # 20+ files
            'system-wide': 10  # Architecture changes
        }
        impact_score = IMPACT_SCORES.get(impact_scope, 5)

        # UNCERTAINTY SCORE MAPPING
        # Lower confidence = higher uncertainty score
        if confidence >= 0.9:
            uncertainty_score = 1
        elif confidence >= 0.7:
            uncertainty_score = 3
        elif confidence >= 0.5:
            uncertainty_score = 5
        elif confidence >= 0.3:
            uncertainty_score = 7
        else:
            uncertainty_score = 9

        # G-SCORE CALCULATION
        g_score = impact_score * uncertainty_score

        # ROUTING DECISION
        if g_score <= system1_max:
            processing_path = 'system1'
            confirmation_required = False
        elif g_score > confirm_above:
            processing_path = 'system2'
            confirmation_required = True
        else:
            processing_path = 'system2'
            confirmation_required = False

        # Category-based overrides:
        # - action/debugging always use System 2 (they modify things)
        # - existence/understanding prefer System 1 (read-only)
        ACTION_CATEGORIES = {'action', 'debugging', 'quality'}
        if category in ACTION_CATEGORIES and processing_path == 'system1':
            # Bump action categories to System 2 if they were borderline
            if g_score >= system1_max - 2:
                processing_path = 'system2'

        result = {
            'g_score': g_score,
            'impact_score': impact_score,
            'uncertainty_score': uncertainty_score,
            'impact_scope': impact_scope,
            'confidence': confidence,
            'processing_path': processing_path,
            'confirmation_required': confirmation_required,
            'thresholds': {
                'system1_max': system1_max,
                'confirm_above': confirm_above,
                'base_system1_max': base_system1_max,
                'base_confirm_above': base_confirm_above
            },
            # Include caution info
            'caution': {
                'level': caution_level,
                'homeostatic_enabled': homeostatic_enabled,
                'threshold_multiplier': round(1.0 / caution_level, 2) if caution_level > 0 else 1.0
            }
        }

        print(json.dumps(result))
        EOF
      env:
        IMPACT_SCOPE: "{{ blocks.attempt.outputs.response.result.impact_scope | default('moderate') }}"
        CONFIDENCE: "{{ blocks.attempt.outputs.response.confidence }}"
        CATEGORY: "{{ blocks.attempt.outputs.response.result.category }}"
        THRESHOLDS: "{{ inputs.features.g_score_thresholds | default({}) | tojson }}"
        CAUTION_LEVEL: "{{ inputs.caution_level | default(1.0) }}"
        HOMEOSTATIC_ENABLED: "{{ inputs.features.homeostatic_enabled | default(false) }}"

  - id: needs_investigation
    type: Shell
    description: Evaluate whether to spawn investigation cell.
    depends_on: [attempt]
    inputs:
      command: |
        python3 << 'EOF'
        import json, os

        confidence = float(os.environ.get('CONFIDENCE', '1'))
        threshold = float(os.environ.get('THRESHOLD', '0.7'))
        uncertainty_exists = os.environ.get('UNCERTAINTY_EXISTS', 'false').lower() == 'true'
        question = os.environ.get('UNCERTAINTY_QUESTION', '').strip()
        depth = int(os.environ.get('DEPTH', '0'))
        max_depth = int(os.environ.get('MAX_DEPTH', '5'))

        should_investigate = (
            confidence < threshold and
            uncertainty_exists and
            question != '' and
            depth < max_depth
        )

        if confidence >= threshold:
            reason = 'confident'
        elif not uncertainty_exists or not question:
            reason = 'no_uncertainty'
        elif depth >= max_depth:
            reason = 'max_depth_reached'
        else:
            reason = 'investigating'

        print(json.dumps({
            'should_investigate': should_investigate,
            'reason': reason,
            'confidence': confidence,
            'depth': depth
        }))
        EOF
      env:
        CONFIDENCE: "{{ blocks.attempt.outputs.response.confidence }}"
        THRESHOLD: "{{ inputs.confidence_threshold }}"
        UNCERTAINTY_EXISTS: "{{ blocks.attempt.outputs.response.uncertainty.exists | default(false) }}"
        UNCERTAINTY_QUESTION: "{{ blocks.attempt.outputs.response.uncertainty.question | default('') }}"
        DEPTH: "{{ inputs.depth }}"
        MAX_DEPTH: "{{ inputs.max_depth }}"

  - id: lookup_config
    type: Shell
    description: Map category to v2 pipeline_config (includes execute/decide/verify).
    depends_on: [attempt]
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        MAPPING = {
            "existence": {
                "gather": {"depth": "shallow", "spawn": "never"},
                "execute": {"enabled": False},
                "reason": {"goal": "verify", "hypothesis_mode": False},
                "decide": {"verify_required": False},
                "act": {"trigger": "never", "mode": None},
                "verify": {"enabled": False, "max_retries": 0}
            },
            "understanding": {
                "gather": {"depth": "focused", "spawn": "complex_only"},
                "execute": {"enabled": False},
                "reason": {"goal": "explain", "hypothesis_mode": False},
                "decide": {"verify_required": False},
                "act": {"trigger": "never", "mode": None},
                "verify": {"enabled": False, "max_retries": 0}
            },
            "discovery": {
                "gather": {"depth": "broad", "spawn": "always"},
                "execute": {"enabled": False},
                "reason": {"goal": "enumerate", "hypothesis_mode": False},
                "decide": {"verify_required": False},
                "act": {"trigger": "never", "mode": None},
                "verify": {"enabled": False, "max_retries": 0}
            },
            "quality": {
                "gather": {"depth": "focused", "spawn": "complex_only"},
                "execute": {"enabled": True, "type": "lint_and_test"},
                "reason": {"goal": "evaluate", "hypothesis_mode": False},
                "decide": {"verify_required": False},
                "act": {"trigger": "findings_require", "mode": "report"},
                "verify": {"enabled": False, "max_retries": 0}
            },
            "planning": {
                "gather": {"depth": "focused", "spawn": "complex_only"},
                "execute": {"enabled": False},
                "reason": {"goal": "plan", "hypothesis_mode": False},
                "decide": {"verify_required": False},
                "act": {"trigger": "never", "mode": None},
                "verify": {"enabled": False, "max_retries": 0}
            },
            "debugging": {
                "gather": {"depth": "deep", "spawn": "complex_only"},
                "execute": {"enabled": True, "type": "inferred"},
                "reason": {"goal": "diagnose", "hypothesis_mode": True},
                "decide": {"verify_required": True, "max_hypotheses": 3},
                "act": {"trigger": "findings_require", "mode": "fix"},
                "verify": {"enabled": True, "max_retries": 5}
            },
            "action": {
                "gather": {"depth": "deep", "spawn": "complex_only"},
                "execute": {"enabled": True, "type": "inferred"},
                "reason": {"goal": "plan", "hypothesis_mode": False},
                "decide": {"verify_required": True},
                "act": {"trigger": "always", "mode": "implement"},
                "verify": {"enabled": True, "max_retries": 3}
            }
        }

        category = os.environ.get('CATEGORY', 'understanding')
        config = MAPPING.get(category, MAPPING['understanding'])

        print(json.dumps({
            "category": category,
            "pipeline_config": config
        }))
        EOF
      env:
        CATEGORY: "{{ blocks.attempt.outputs.response.result.category }}"

  - id: investigate
    type: Workflow
    description: Spawn cortex-cell to investigate uncertainty.
    depends_on: [needs_investigation, lookup_config]
    condition: "{{ get(blocks.needs_investigation.outputs.stdout, 'should_investigate', false) }}"
    inputs:
      workflow: cortex-cell
      inputs:
        prompt: "{{ blocks.attempt.outputs.response.uncertainty.question }}"
        context:
          repo_path: "{{ inputs.context.repo_path | default('') }}"
          parent_prompt: "{{ inputs.prompt }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ get(blocks.register_phase.outputs, 'rows.0.id', '') }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"
        features: "{{ inputs.features }}"

  - id: self_recurse
    type: Workflow
    description: Call THIS phase with synthesis from investigation.
    depends_on: [investigate]
    condition: "{{ blocks.investigate.succeeded }}"
    inputs:
      workflow: cortex-phase-categorize
      inputs:
        prompt: "{{ inputs.prompt }}"
        system: "{{ inputs.system }}"
        context: "{{ inputs.context }}"
        memory: "{{ inputs.memory }}"
        state: "{{ inputs.state }}"
        models: "{{ inputs.models }}"
        parent_id: "{{ inputs.parent_id }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"
        features: "{{ inputs.features }}"
        max_depth: "{{ inputs.max_depth }}"
        depth: "{{ inputs.depth + 1 }}"
        synthesis: |
          {{ inputs.synthesis + [{
            'prompt': blocks.attempt.outputs.response.uncertainty.question,
            'response': blocks.investigate.outputs.response,
            'synthesis': blocks.investigate.outputs.synthesis
          }] }}

  - id: track_done
    type: Sql
    description: Mark phase complete.
    depends_on:
      - block: register_phase
        required: true
      - block: attempt
        required: true
      - block: lookup_config
        required: true
      - block: self_recurse
        required: false
      - block: form_expectation
        required: false
      - block: store_expectation
        required: false
      - block: compute_g_score
        required: false
      - block: query_heuristics
        required: false
    condition: "{{ blocks.register_phase.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: update
      where:
        id: "{{ get(blocks.register_phase.outputs, 'rows.0.id', '') }}"
      data:
        status: done
        outputs: |
          {{
            {
              'recursed': blocks.self_recurse.succeeded,
              'category': get(blocks.attempt.outputs.response.result, 'category', 'understanding'),
              'g_score': get(blocks.compute_g_score.outputs.stdout, 'g_score', 25) if blocks.compute_g_score.succeeded else 25,
              'processing_path': get(blocks.compute_g_score.outputs.stdout, 'processing_path', 'system2') if blocks.compute_g_score.succeeded else 'system2',
              'expectation_id': get(blocks.store_expectation.outputs, 'rows.0.id', '') if blocks.store_expectation.succeeded else '',
              'context_hash': get(blocks.form_expectation.outputs.stdout, 'context_hash', '') if blocks.form_expectation.succeeded else '',
              'heuristics_count': blocks.query_heuristics.outputs.count if blocks.query_heuristics.succeeded else 0,
              'routing': blocks.compute_g_score.outputs.stdout if blocks.compute_g_score.succeeded else {}
            } | tojson
          }}

outputs:
  result:
    type: dict
    description: "Categorization result."
    value: |
      {{ blocks.self_recurse.outputs.result if blocks.self_recurse.succeeded
         else blocks.attempt.outputs.response.result }}

  pipeline_config:
    type: dict
    description: "Pipeline configuration with execute/decide/verify fields."
    value: |
      {{ blocks.self_recurse.outputs.pipeline_config if blocks.self_recurse.succeeded
         else get(blocks.lookup_config.outputs.stdout, 'pipeline_config', {}) }}

  expectation_id:
    type: str
    description: "ID of the expectation formed (predictive coding)."
    value: |
      {{ blocks.self_recurse.outputs.expectation_id if blocks.self_recurse.succeeded
         else get(blocks.store_expectation.outputs, 'rows.0.id', '') }}

  context_hash:
    type: str
    description: "Context hash for clustering similar situations."
    value: |
      {{ get(blocks.form_expectation.outputs.stdout, 'context_hash', '') }}

  expectation:
    type: dict
    description: "Full expectation object for REASON phase context."
    value: |
      {{ blocks.form_expectation.outputs.stdout if blocks.form_expectation.succeeded else {} }}

  matched_heuristics:
    type: list
    description: "Heuristics matched for this query (memory consolidation)."
    value: |
      {{ blocks.query_heuristics.outputs.heuristics if blocks.query_heuristics.succeeded else [] }}

  heuristics_count:
    type: num
    description: "Number of heuristics matched."
    value: |
      {{ blocks.query_heuristics.outputs.count if blocks.query_heuristics.succeeded else 0 }}

  g_score:
    type: num
    description: "G-Score for dual-track routing (Impact * Uncertainty)."
    value: |
      {{ get(blocks.compute_g_score.outputs.stdout, 'g_score', 25) if blocks.compute_g_score.succeeded else 25 }}

  routing:
    type: dict
    description: "Dual-track routing decision."
    value: |
      {{ blocks.compute_g_score.outputs.stdout if blocks.compute_g_score.succeeded else {
        'processing_path': 'system2',
        'g_score': 25,
        'confirmation_required': false
      } }}

  processing_path:
    type: str
    description: "Processing path: system1 (fast) or system2 (full)."
    value: |
      {{ get(blocks.compute_g_score.outputs.stdout, 'processing_path', 'system2') if blocks.compute_g_score.succeeded else 'system2' }}

  confirmation_required:
    type: bool
    description: "Whether user confirmation is required (G-Score > 50)."
    value: |
      {{ get(blocks.compute_g_score.outputs.stdout, 'confirmation_required', false) if blocks.compute_g_score.succeeded else false }}

  state:
    type: str
    description: "Path to state database."
    value: "{{ inputs.state }}"
