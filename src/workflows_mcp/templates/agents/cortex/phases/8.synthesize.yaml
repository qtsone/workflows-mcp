# =============================================================================
# CORTEX Synthesize Phase
# =============================================================================
#
# Captures learnings when verification succeeds (or for done actions).
# This is the terminal phase that documents:
#   - Root cause analysis
#   - Detection patterns for future debugging
#   - Recommendations for prevention
#
# Enhancement: Records episodes for memory consolidation.
# Episodes are later processed by CONSOLIDATE phase to generate heuristics.
#
# =============================================================================

name: cortex-phase-synthesize
description: "CORTEX Synthesize Phase - capture learnings and record episodes"

tags: [cortex, phase, synthesize, learning, episodes]

inputs:
  prompt:
    type: str
    description: The original prompt.
    required: true

  context:
    type: dict
    description: Context including synthesis and verification results.
    default: {}

  state:
    type: str
    description: Path to SQLite state database.
    required: true

  models:
    type: dict
    description: Model definitions.
    default: {}

  parent_id:
    type: str
    description: Parent task ID.
    default: ""

  features:
    type: dict
    description: Feature toggles.
    default:
      expectations_enabled: false

  expectation_id:
    type: str
    description: ID of expectation from CATEGORIZE.
    default: ""

  surprisal:
    type: dict
    description: Surprisal result from REASON phase.
    default: {}

  context_hash:
    type: str
    description: Context hash for clustering.
    default: ""

  category:
    type: str
    description: Task category from CATEGORIZE.
    default: "understanding"

  actions_taken:
    type: list
    description: Actions taken during the task.
    default: []

blocks:
  # ===========================================================================
  # STEP 1: Register Phase Task
  # ===========================================================================
  - id: register_phase
    type: Sql
    description: Register this phase in the task tree.
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: insert
      data:
        parent_id: "{{ inputs.parent_id if inputs.parent_id else none }}"
        kind: phase
        name: synthesize
        metadata: "{{ {'labels': {'phase_order': 8}} }}"
        inputs: "{{ {'prompt': inputs.prompt} }}"
        status: running

  # ===========================================================================
  # STEP 2: Generate Learning Summary
  # ===========================================================================
  - id: generate_learnings
    type: Shell
    description: Generate learning summary from the session.
    depends_on: [register_phase]
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os

        synthesis_json = os.environ.get('SYNTHESIS', '{}')
        verification_json = os.environ.get('VERIFICATION', '{}')
        category = os.environ.get('CATEGORY', 'understanding')

        try:
            synthesis = json.loads(synthesis_json) if synthesis_json else {}
        except:
            synthesis = {}

        try:
            verification = json.loads(verification_json) if verification_json else {}
        except:
            verification = {}

        learnings = {
            'category': category,
            'success': verification.get('passed', True),
            'findings_summary': synthesis.get('summary', ''),
            'root_cause': None,
            'detection_patterns': [],
            'recommendations': synthesis.get('recommendations', []),
            'metadata': {
                'findings_count': len(synthesis.get('findings', [])),
                'verification_comparison': verification.get('comparison', {})
            }
        }

        # Extract root cause if this was debugging
        if category == 'debugging':
            findings = synthesis.get('findings', [])
            root_causes = [f for f in findings if f.get('evidence_type') == 'root_cause']
            if root_causes:
                learnings['root_cause'] = root_causes[0].get('claim')

            # Generate detection patterns from findings
            for finding in findings:
                if finding.get('grounding'):
                    for ground in finding.get('grounding', []):
                        if ground.get('type') == 'code':
                            learnings['detection_patterns'].append({
                                'pattern': ground.get('content', '')[:200],
                                'file': ground.get('source', '')
                            })

        # Add verification insights
        if verification.get('comparison'):
            comparison = verification.get('comparison', {})
            if comparison.get('tests', {}).get('fixed', 0) > 0:
                learnings['fix_summary'] = f"Fixed {comparison['tests']['fixed']} failing tests"

        print(json.dumps(learnings))
        EOF
      env:
        SYNTHESIS: "{{ inputs.context.synthesis | tojson }}"
        VERIFICATION: "{{ inputs.context.verification | tojson }}"
        CATEGORY: "{{ inputs.context.category | default('understanding') }}"

  # ===========================================================================
  # STEP 3: Store Learnings in Memory
  # ===========================================================================
  - id: store_learnings
    type: Sql
    description: Store learnings in memory table for future reference.
    depends_on: [generate_learnings]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        INSERT OR REPLACE INTO memory (namespace, key, value, metadata, task_id)
        VALUES ('learnings', ?, ?, '{}', ?)
      params:
        - "session_{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('unknown') }}"
        - "{{ blocks.generate_learnings.outputs.stdout }}"
        - "{{ inputs.parent_id }}"

  # ===========================================================================
  # STEP 4: Record Episode (Memory Consolidation)
  # ===========================================================================
  - id: build_episode
    type: Shell
    description: Build episode record for memory consolidation.
    depends_on: [generate_learnings]
    condition: "{{ inputs.features.expectations_enabled | default(false) }}"
    inputs:
      command: |
        python3 << 'EOF'
        import json
        import os
        import hashlib

        prompt = os.environ.get('PROMPT', '')
        category = os.environ.get('CATEGORY', 'understanding')
        learnings_json = os.environ.get('LEARNINGS', '{}')
        surprisal_json = os.environ.get('SURPRISAL', '{}')
        actions_json = os.environ.get('ACTIONS', '[]')
        context_hash = os.environ.get('CONTEXT_HASH', '')

        try:
            learnings = json.loads(learnings_json)
        except:
            learnings = {}

        try:
            surprisal = json.loads(surprisal_json)
        except:
            surprisal = {}

        try:
            actions = json.loads(actions_json)
        except:
            actions = []

        # Generate query hash for episode clustering
        query_hash = hashlib.sha256(prompt.encode()).hexdigest()[:16]

        # Determine outcome from learnings and surprisal
        success = learnings.get('success', True)
        outcome = 'success' if success else 'failure'
        if not success and learnings.get('root_cause'):
            outcome = 'failure_diagnosed'

        # Extract context features for clustering similar episodes
        context_features = {
            'category': category,
            'has_execution': bool(learnings.get('metadata', {}).get('verification_comparison')),
            'has_root_cause': bool(learnings.get('root_cause')),
            'findings_count': learnings.get('metadata', {}).get('findings_count', 0),
            'context_hash': context_hash
        }

        # Get surprisal value
        surprisal_bits = surprisal.get('surprisal_bits', 0)

        # Extract learnings for storage
        extracted_learnings = []
        if learnings.get('root_cause'):
            extracted_learnings.append({'type': 'root_cause', 'content': learnings['root_cause']})
        for rec in learnings.get('recommendations', []):
            extracted_learnings.append({'type': 'recommendation', 'content': rec})
        for pattern in learnings.get('detection_patterns', []):
            extracted_learnings.append({'type': 'detection_pattern', 'content': pattern})

        episode = {
            'query_hash': query_hash,
            'category': category,
            'context_features': context_features,
            'actions_taken': actions,
            'outcome': outcome,
            'surprisal_bits': surprisal_bits,
            'learnings': extracted_learnings
        }

        print(json.dumps(episode))
        EOF
      env:
        PROMPT: "{{ inputs.prompt }}"
        CATEGORY: "{{ inputs.category }}"
        LEARNINGS: "{{ blocks.generate_learnings.outputs.stdout }}"
        SURPRISAL: "{{ inputs.surprisal | tojson }}"
        ACTIONS: "{{ inputs.actions_taken | tojson }}"
        CONTEXT_HASH: "{{ inputs.context_hash }}"

  - id: store_episode
    type: Sql
    description: Store episode in database for consolidation.
    depends_on: [build_episode]
    condition: "{{ blocks.build_episode.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.episode }}"
      op: insert
      data:
        query_hash: "{{ (blocks.build_episode.outputs.stdout | fromjson).query_hash }}"
        category: "{{ (blocks.build_episode.outputs.stdout | fromjson).category }}"
        context_features: "{{ (blocks.build_episode.outputs.stdout | fromjson).context_features }}"
        actions_taken: "{{ (blocks.build_episode.outputs.stdout | fromjson).actions_taken }}"
        outcome: "{{ (blocks.build_episode.outputs.stdout | fromjson).outcome }}"
        surprisal_bits: "{{ (blocks.build_episode.outputs.stdout | fromjson).surprisal_bits }}"
        learnings: "{{ (blocks.build_episode.outputs.stdout | fromjson).learnings }}"

  # ===========================================================================
  # STEP 5: Mark Phase Complete
  # ===========================================================================
  - id: track_done
    type: Sql
    description: Mark phase complete.
    depends_on:
      - block: register_phase
        required: true
      - block: generate_learnings
        required: true
      - block: store_learnings
        required: false
      - block: store_episode
        required: false
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        UPDATE tasks
        SET status = 'done',
            outputs = ?,
            updated_at = datetime('now')
        WHERE id = ?
      params:
        - "{{ blocks.generate_learnings.outputs.stdout }}"
        - "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"

# =============================================================================
# OUTPUTS
# =============================================================================
outputs:
  learnings:
    type: dict
    description: "Captured learnings from the session."
    value: "{{ blocks.generate_learnings.outputs.stdout | fromjson }}"

  success:
    type: bool
    description: "Whether the overall task succeeded."
    value: "{{ (blocks.generate_learnings.outputs.stdout | fromjson).success | default(true) }}"

  episode_id:
    type: str
    description: "ID of the episode recorded (memory consolidation)."
    value: "{{ (blocks.store_episode.outputs.rows | default([{}]))[0].id | default('') }}"

  episode:
    type: dict
    description: "Episode data recorded for consolidation."
    value: "{{ blocks.build_episode.outputs.stdout | fromjson if blocks.build_episode.succeeded else {} }}"

  state:
    type: str
    description: "Path to state database."
    value: "{{ inputs.state }}"
