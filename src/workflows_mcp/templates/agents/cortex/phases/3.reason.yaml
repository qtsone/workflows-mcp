# =============================================================================
# CORTEX Reason Phase (v2)
# =============================================================================
#
# MERGED ANALYZE + SYNTHESIZE into unified REASON phase.
#
# Responsibilities:
#   1. Retrieve evidence from memory (outlines + content)
#   2. Query ALL child cells from task tree for their syntheses
#   3. Analyze with goal focus (from pipeline_config.reason.goal)
#   4. Produce unified synthesis + response
#   5. Set actions_needed based on findings
#   6. May output config_override for ACT phase
#
# Goals (from pipeline_config.reason.goal):
#   - verify: Simple yes/no with evidence
#   - explain: Teach and clarify
#   - evaluate: Assess quality, find issues
#   - plan: Create action plan
#   - diagnose: Find root cause
#   - enumerate: List all findings
#
# Follows universal fractal pattern with memory retrieval + child querying.
#
# =============================================================================

name: cortex-phase-reason
description: "CORTEX Reason Phase - analyzes evidence and synthesizes conclusions"

tags: [cortex, phase, reason, v2]

inputs:
  prompt:
    type: str
    description: The original query.
    required: true

  system:
    type: str
    description: System prompt override.
    default: |
      You are the reasoning module of a recursive cognitive system (CORTEX).
      Your role is to analyze evidence and synthesize unified conclusions.

      Rules:
      1. Cite evidence - Every finding MUST reference specific file paths and lines
      2. Rate severity - critical, high, medium, low, info
      3. Deduplicate - Same finding from multiple sources → one entry
      4. Resolve conflicts - Contradictions → prefer higher-evidence source
      5. Chain evidence - Maintain trails to original sources
      6. Conclude - Produce actionable summary, not just finding list

      Be honest about your confidence. If you're uncertain about the analysis,
      set uncertainty.exists = true and provide a specific question.

  context:
    type: dict
    description: Context including gather_result, category, repo_path, etc.
    default: {}

  pipeline_config:
    type: dict
    description: Pipeline configuration from CATEGORIZE (with any overrides).
    default: {}

  memory:
    type: list
    description: List of memory keys to retrieve (file paths).
    default: []

  synthesis:
    type: list
    description: Accumulated synthesis from previous investigations.
    default: []

  depth:
    type: num
    description: Current recursion depth.
    default: 0

  max_depth:
    type: num
    description: Maximum recursion depth.
    default: 5

  iterations:
    type: num
    description: Current task completion iteration.
    default: 0

  max_iterations:
    type: num
    description: Maximum continuation attempts.
    default: 3

  confidence_threshold:
    type: num
    description: Minimum confidence to skip investigation.
    default: 0.7

  state:
    type: str
    description: Path to SQLite state database.
    default: ""

  models:
    type: dict
    description: Model definitions for CRUD operations.
    default: {}

  parent_id:
    type: str
    description: Parent cell's task ID (for child querying).
    default: ""

  profile:
    type: str
    description: LLM profile to use.
    default: "default"

  capabilities:
    type: list
    description: Available capabilities registry (filtered by permissions).
    default: []

  permissions:
    type: dict
    description: Permission flags for capability filtering.
    default: { "read": true, "write": false, "execute": false }

blocks:
  # ===========================================================================
  # STEP 1: Register Phase Task (model-based insert with auto UUID)
  # ===========================================================================
  - id: register_phase
    type: Sql
    description: Register this phase in the task tree.
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.task }}"
      op: insert
      data:
        parent_id: "{{ inputs.parent_id if inputs.parent_id else none }}"
        kind: phase
        name: reason
        metadata: "{{ {'labels': {'phase_order': 3, 'goal': inputs.pipeline_config.reason.goal | default('explain')}} }}"
        inputs: "{{ {'prompt': inputs.prompt} }}"
        status: running
        depth: "{{ inputs.depth }}"

  # ===========================================================================
  # STEP 2: Retrieve evidence (outlines) from memory table
  # ===========================================================================
  - id: retrieve_outlines
    type: Sql
    description: Get gathered outlines from memory (namespace=outline).
    depends_on: [register_phase]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT namespace as evidence_type, key, value, metadata,
               json_extract(metadata, '$.byte_size') as byte_size
        FROM memory
        WHERE namespace = 'outline'
        ORDER BY key
        LIMIT 100

  # ===========================================================================
  # STEP 3: Retrieve evidence (content) from memory table
  # ===========================================================================
  - id: retrieve_content
    type: Sql
    description: Get gathered file contents from memory (namespace=content).
    depends_on: [register_phase]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT namespace as evidence_type, key, value, metadata,
               json_extract(metadata, '$.byte_size') as byte_size
        FROM memory
        WHERE namespace = 'content'
        ORDER BY key
        LIMIT 100

  # ===========================================================================
  # STEP 3b: Retrieve all episodic evidence from memory
  # ===========================================================================
  - id: retrieve_evidence
    type: Sql
    description: Query all gathered evidence from memory.
    depends_on: [register_phase]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT namespace as evidence_type, key, value, metadata,
               json_extract(metadata, '$.byte_size') as byte_size
        FROM memory
        WHERE namespace IN ('content', 'outline', 'search')
        ORDER BY namespace, key
        LIMIT 100

  # ===========================================================================
  # STEP 3c: Recall existing facts from semantic memory (FTS5)
  # ===========================================================================
  - id: recall_facts
    type: Sql
    description: Query semantic memory for relevant existing facts.
    depends_on: [register_phase]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT f.id, f.claim, f.evidence_type, f.confidence, f.grounding, f.task_id
        FROM facts f
        JOIN facts_fts fts ON f.id = fts.id
        WHERE facts_fts MATCH ?
          AND f.status = 'active'
        ORDER BY f.confidence DESC
        LIMIT 30
      params:
        - "{{ inputs.prompt | truncate(100, True, '') }}"

  # ===========================================================================
  # STEP 4: Query ALL child cells from task tree (direct Sql)
  # ===========================================================================
  - id: get_child_cells
    type: Sql
    description: Query all child cortex-cell syntheses from DB.
    depends_on: [register_phase]
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        SELECT id as task_id, inputs, outputs
        FROM tasks
        WHERE parent_id = ?
          AND kind = 'cell'
          AND status = 'done'
        ORDER BY created_at
      params:
        - "{{ inputs.parent_id }}"

  # ===========================================================================
  # STEP 5: Attempt - Analyze and synthesize
  # ===========================================================================
  - id: attempt
    type: LLMCall
    description: Analyze evidence and produce unified synthesis.
    depends_on:
      - block: register_phase
        required: true
      - block: retrieve_outlines
        required: false
      - block: retrieve_content
        required: false
      - block: retrieve_evidence
        required: false
      - block: recall_facts
        required: false
      - block: get_child_cells
        required: false
    inputs:
      profile: "{{ inputs.profile }}"
      timeout: 600
      system_instructions: "{{ inputs.system }}"
      prompt: |
        # Reasoning Phase

        ## Original Query
        {{ inputs.prompt }}

        ## Goal: {{ inputs.pipeline_config.reason.goal | default('explain') | upper }}

        {% if inputs.context %}
        ## Context
        {{ inputs.context | tojson }}
        {% endif %}

        {% if inputs.context.gather_result %}
        ## Gather Phase Summary
        - **Confidence**: {{ inputs.context.gather_result.confidence | default('N/A') }}
        - **Operations executed**: {{ inputs.context.gather_result.operations_executed | default(0) }}
        - **Questions spawned**: {{ inputs.context.gather_result.questions_spawned | default(0) }}
        {% if inputs.context.gather_result.confidence is defined and inputs.context.gather_result.confidence < 0.7 %}
        **⚠️ WARNING: Low gather confidence. Evidence may be incomplete.**
        {% endif %}
        {% endif %}

        {% if blocks.retrieve_outlines.succeeded and blocks.retrieve_outlines.outputs.row_count > 0 %}
        ## File Outlines ({{ blocks.retrieve_outlines.outputs.row_count }} files)
        {% for item in blocks.retrieve_outlines.outputs.rows %}
        ### {{ item.key }}
        ```
        {{ item.value }}
        ```
        {% endfor %}
        {% endif %}

        {% if blocks.retrieve_content.succeeded and blocks.retrieve_content.outputs.row_count > 0 %}
        ## File Contents ({{ blocks.retrieve_content.outputs.row_count }} files)
        {% for item in blocks.retrieve_content.outputs.rows %}
        ### {{ item.key }}
        ```
        {{ item.value }}
        ```
        {% endfor %}
        {% endif %}

        {% if blocks.retrieve_evidence.succeeded and blocks.retrieve_evidence.outputs.row_count > 0 %}
        ## Episodic Evidence ({{ blocks.retrieve_evidence.outputs.row_count }} items)
        {% for item in blocks.retrieve_evidence.outputs.rows %}
        - **{{ item.key }}** ({{ item.evidence_type }}, {{ item.byte_size }} bytes)
        {% endfor %}
        {% endif %}

        {% if blocks.recall_facts.succeeded and blocks.recall_facts.outputs.row_count > 0 %}
        ## Known Facts (Semantic Memory - {{ blocks.recall_facts.outputs.row_count }} facts)
        These facts were validated in previous reasoning sessions:
        {% for fact in blocks.recall_facts.outputs.rows %}
        - **{{ fact.claim }}**
          - Type: {{ fact.evidence_type }} | Confidence: {{ fact.confidence }}
          {% if fact.grounding %}- Evidence: {{ fact.grounding }}{% endif %}
        {% endfor %}

        NOTE: Build on these facts. If you find contradictions, flag them for conflict resolution.
        {% endif %}

        {% if blocks.get_child_cells.succeeded and blocks.get_child_cells.outputs.rows | length > 0 %}
        ## Child Cell Syntheses ({{ blocks.get_child_cells.outputs.rows | length }} cells)
        {% for child in blocks.get_child_cells.outputs.rows %}
        ### Child Cell {{ loop.index }} ({{ child.task_id }})
        {# v1 schema: prompt in inputs, response/synthesis in outputs #}
        - **Query**: {{ child.inputs.prompt | default('N/A') }}
        - **Answer**: {{ child.outputs.response | default('N/A') }}
        {% if child.outputs.synthesis %}
        - **Synthesis Summary**: {{ child.outputs.synthesis.summary | default('N/A') }}
        - **Confidence**: {{ child.outputs.synthesis.confidence | default('N/A') }}
        {% endif %}
        {% endfor %}
        {% endif %}

        {% if inputs.synthesis | length > 0 %}
        ## Previous Investigations
        {% for c in inputs.synthesis %}
        ### Investigation {{ loop.index }}
        - Question: {{ c.prompt }}
        - Answer: {{ c.response }}
        {% if c.synthesis %}
        - Key Findings: {{ c.synthesis.summary | default('N/A') }}
        {% endif %}
        {% endfor %}
        {% endif %}

        ## Reasoning Instructions

        Apply the **{{ inputs.pipeline_config.reason.goal | default('explain') | upper }}** goal:

        {% if inputs.pipeline_config.reason.goal == 'verify' %}
        - Answer with YES or NO
        - Cite specific evidence for your answer
        - High confidence required
        {% elif inputs.pipeline_config.reason.goal == 'explain' %}
        - Explain what the code/system does
        - Be educational and thorough
        - Include relevant examples
        {% elif inputs.pipeline_config.reason.goal == 'evaluate' %}
        - Assess quality, identify issues
        - Rate by severity (critical, high, medium, low, info)
        - Provide specific recommendations
        {% elif inputs.pipeline_config.reason.goal == 'plan' %}
        - Create a step-by-step plan
        - Identify dependencies and risks
        - Order steps by priority
        {% elif inputs.pipeline_config.reason.goal == 'diagnose' %}
        - Find root cause of the issue
        - Trace the problem path
        - Suggest specific fixes
        {% elif inputs.pipeline_config.reason.goal == 'enumerate' %}
        - List ALL instances found
        - Group by category if applicable
        - Include locations and counts
        {% else %}
        - Analyze the evidence thoroughly
        - Synthesize into unified conclusions
        {% endif %}

        ## Output Requirements

        1. **Every finding MUST cite specific evidence** (file paths, line numbers)
        2. **Determine if actions are needed** based on your synthesis
        3. **Set config_override** if you discover ACT needs different settings

        ## Questions (Parallel Sub-Investigations)

        **Questions = How you express uncertainty.** When analysis reveals gaps, ASK:

        | Confidence | Expected Action |
        |------------|-----------------|
        | 0.9 - 1.0  | Proceed with synthesis only |
        | 0.7 - 0.9  | Consider targeted questions |
        | 0.5 - 0.7  | **SHOULD** ask questions to clarify |
        | < 0.5      | **MUST** ask questions before concluding |

        Example:
        ```yaml
        questions:
          - prompt: "What are the security implications of this pattern?"
            reason: "Need deeper security analysis"
          - prompt: "How does this interact with the authentication system?"
            reason: "Potential cross-cutting concern"
        ```

        **Key rules:**
        1. Questions spawn SEPARATE cognitive cycles (child cells)
        2. Only ask questions about DIFFERENT aspects than current analysis
        3. Do NOT restate the parent prompt

        Spawn policy: {{ inputs.pipeline_config.reason.spawn | default('uncertain_only') }}

      response_schema:
        type: object
        properties:
          synthesis:
            type: object
            description: "Unified synthesis (OUTPUT)"
            properties:
              findings:
                type: array
                items:
                  type: object
                  properties:
                    claim:
                      type: string
                    severity:
                      type: string
                      enum: [critical, high, medium, low, info]
                    confidence:
                      type: number
                    evidence_chain:
                      type: array
                      items:
                        type: string
                  required: [claim, severity, confidence]
              summary:
                type: string
              risk_level:
                type: string
                enum: [critical, high, medium, low, info]
              recommendations:
                type: array
                items:
                  type: string
              actions_needed:
                type: boolean
            required: [findings, summary, risk_level, actions_needed]
          response:
            type: string
            description: "Direct response to the query (OUTPUT)"
          questions:
            type: array
            description: "Questions requiring child cells to answer (spawns parallel investigations)"
            items:
              type: object
              properties:
                prompt:
                  type: string
                  description: "What to ask/investigate"
                reason:
                  type: string
                  description: "Why this question needs answering"
              required: [prompt, reason]
          config_override:
            type: object
            description: "Override ACT config based on discoveries (OUTPUT)"
            properties:
              act:
                type: object
                properties:
                  trigger:
                    type: string
                    enum: [never, findings_require, always]
                  mode:
                    type: string
                    enum: [none, report, implement, fix, verify]
          confidence:
            type: number
            minimum: 0
            maximum: 1
            description: "Overall confidence (INTERNAL)"
          uncertainty:
            type: object
            description: "What you need to know (INTERNAL)"
            properties:
              exists:
                type: boolean
              question:
                type: string
            required: [exists]
        required: [synthesis, response, confidence, uncertainty]

  # ===========================================================================
  # STEP 5b: Store LLM call for debugging
  # ===========================================================================
  - id: store_llm_call
    type: Sql
    description: Store LLM call details for debugging and analysis.
    depends_on:
      - block: attempt
        required: false
    condition: "{{ inputs.state | trim != '' and blocks.attempt.succeeded }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      model: "{{ inputs.models.llm_call }}"
      op: insert
      data:
        task_id: "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"
        phase: reason
        system_instructions: "{{ inputs.system | default('') }}"
        prompt: "{{ inputs.prompt }}"
        response: "{{ blocks.attempt.outputs.response }}"
        model: "{{ blocks.attempt.outputs.metadata.model | default('unknown') }}"
        prompt_tokens: "{{ blocks.attempt.outputs.metadata.usage.prompt_tokens | default(0) }}"
        completion_tokens: "{{ blocks.attempt.outputs.metadata.usage.completion_tokens | default(0) }}"
        duration_ms: "{{ blocks.attempt.metadata.duration_ms | default(0) }}"

  # ===========================================================================
  # STEP 6: Check if investigation needed
  # ===========================================================================
  - id: needs_investigation
    type: Shell
    description: Evaluate whether to spawn investigation cell.
    depends_on: [attempt]
    inputs:
      command: |
        python3 << 'EOF'
        import json, os

        confidence = float(os.environ.get('CONFIDENCE', '1'))
        threshold = float(os.environ.get('THRESHOLD', '0.7'))
        uncertainty_exists = os.environ.get('UNCERTAINTY_EXISTS', 'false').lower() == 'true'
        question = os.environ.get('UNCERTAINTY_QUESTION', '').strip()
        depth = int(os.environ.get('DEPTH', '0'))
        max_depth = int(os.environ.get('MAX_DEPTH', '5'))
        spawn_policy = os.environ.get('SPAWN_POLICY', 'uncertain_only')

        # Spawn policy determines when to investigate
        # never: Never spawn investigations
        # uncertain_only: Spawn only when uncertain
        # always: Always spawn (not recommended for REASON)
        allow_spawn = spawn_policy != 'never'

        should_investigate = (
            allow_spawn and
            confidence < threshold and
            uncertainty_exists and
            question != '' and
            depth < max_depth
        )

        if spawn_policy == 'never':
            reason = 'spawn_disabled'
        elif confidence >= threshold:
            reason = 'confident'
        elif not uncertainty_exists or not question:
            reason = 'no_uncertainty'
        elif depth >= max_depth:
            reason = 'max_depth_reached'
        else:
            reason = 'investigating'

        print(json.dumps({
            'should_investigate': should_investigate,
            'reason': reason,
            'confidence': confidence,
            'depth': depth,
            'spawn_policy': spawn_policy
        }))
        EOF
      env:
        CONFIDENCE: "{{ blocks.attempt.outputs.response.confidence }}"
        THRESHOLD: "{{ inputs.confidence_threshold }}"
        UNCERTAINTY_EXISTS: "{{ blocks.attempt.outputs.response.uncertainty.exists | default(false) }}"
        UNCERTAINTY_QUESTION: "{{ blocks.attempt.outputs.response.uncertainty.question | default('') }}"
        DEPTH: "{{ inputs.depth }}"
        MAX_DEPTH: "{{ inputs.max_depth }}"
        SPAWN_POLICY: "{{ inputs.pipeline_config.reason.spawn | default('uncertain_only') }}"

  # ===========================================================================
  # STEP 6b: Store findings as facts in semantic memory (direct Sql INSERT)
  # ===========================================================================
  - id: store_facts
    type: Sql
    description: Store synthesized findings as facts.
    depends_on: [needs_investigation]
    condition: |
      {{ not (blocks.needs_investigation.outputs.stdout | fromjson).should_investigate
         and (blocks.attempt.outputs.response.synthesis.findings | default([]) | length > 0) }}
    for_each: "{{ blocks.attempt.outputs.response.synthesis.findings }}"
    for_each_mode: parallel
    max_parallel: 10
    continue_on_error: true
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        INSERT INTO facts (id, claim, evidence_type, severity, confidence, grounding, task_id, status)
        VALUES (
          lower(hex(randomblob(16))),
          ?,
          ?,
          ?,
          ?,
          ?,
          ?,
          'active'
        )
        RETURNING id, claim, severity, confidence
      params:
        - "{{ each.value.claim }}"
        - "{{ 'direct' if each.value.confidence >= 0.9 else ('inferred' if each.value.confidence >= 0.7 else 'assumed') }}"
        - "{{ each.value.severity | default('info') }}"
        - "{{ each.value.confidence }}"
        - "{{ each.value.evidence_chain | default([]) | tojson }}"
        - "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"

  # ===========================================================================
  # STEP 6c: Check for conflicting facts (direct Sql with FTS5)
  # ===========================================================================
  - id: check_conflicts
    type: Sql
    description: Detect conflicts between new findings and existing facts.
    depends_on: [store_facts]
    condition: "{{ blocks.store_facts.succeeded and blocks.store_facts.metadata.count > 0 }}"
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        -- Find potentially conflicting facts using FTS5
        -- A conflict is a fact with similar claim but different status or source
        SELECT f.id, f.claim, f.confidence, f.task_id,
               (f.task_id != ?) as potential_conflict
        FROM facts f
        WHERE f.status = 'active'
          AND f.task_id != ?
        ORDER BY f.confidence DESC
        LIMIT 20
      params:
        - "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"
        - "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"

  # ===========================================================================
  # STEP 7: Spawn child cell to investigate
  # ===========================================================================
  - id: investigate
    type: Workflow
    description: Spawn cortex-cell to investigate uncertainty.
    depends_on: [needs_investigation]
    condition: "{{ (blocks.needs_investigation.outputs.stdout | fromjson).should_investigate }}"
    inputs:
      workflow: cortex-cell
      inputs:
        prompt: "{{ blocks.attempt.outputs.response.uncertainty.question }}"
        context:
          repo_path: "{{ inputs.context.repo_path | default('') }}"
          parent_prompt: "{{ inputs.prompt }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: 0
        max_iterations: "{{ inputs.max_iterations }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"

  # ===========================================================================
  # STEP 8: Self-recurse with accumulated synthesis
  # ===========================================================================
  - id: self_recurse
    type: Workflow
    description: Call THIS phase with synthesis from investigation.
    depends_on: [investigate]
    condition: "{{ blocks.investigate.succeeded }}"
    inputs:
      workflow: cortex-phase-reason
      inputs:
        prompt: "{{ inputs.prompt }}"
        system: "{{ inputs.system }}"
        context: "{{ inputs.context }}"
        pipeline_config: "{{ inputs.pipeline_config }}"
        memory: "{{ inputs.memory }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ inputs.parent_id }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"
        max_depth: "{{ inputs.max_depth }}"
        depth: "{{ inputs.depth + 1 }}"
        iterations: "{{ inputs.iterations }}"
        max_iterations: "{{ inputs.max_iterations }}"
        synthesis: |
          {{ inputs.synthesis + [{
            'prompt': blocks.attempt.outputs.response.uncertainty.question,
            'response': blocks.investigate.outputs.response,
            'synthesis': blocks.investigate.outputs.synthesis
          }] }}

  # ===========================================================================
  # STEP 8b: Dispatch questions via for_each (parallel sub-investigations)
  # ===========================================================================
  - id: questions
    type: Workflow
    description: Spawn child cortex-cells to answer questions.
    depends_on: [needs_investigation]
    condition: |
      {{ not (blocks.needs_investigation.outputs.stdout | fromjson).should_investigate
         and (blocks.attempt.outputs.response.questions | default([]) | length > 0)
         and inputs.pipeline_config.reason.spawn != 'never'
         and inputs.depth < inputs.max_depth }}
    for_each: "{{ blocks.attempt.outputs.response.questions }}"
    for_each_mode: parallel
    max_parallel: 3
    continue_on_error: true
    inputs:
      workflow: cortex-cell
      inputs:
        prompt: "{{ each.value.prompt }}"
        context: "{{ inputs.context | combine({'parent_prompt': inputs.prompt, 'spawn_reason': each.value.reason}) }}"
        depth: "{{ inputs.depth + 1 }}"
        max_depth: "{{ inputs.max_depth }}"
        iterations: 0
        max_iterations: "{{ inputs.max_iterations }}"
        state: "{{ inputs.state }}"
        parent_id: "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"
        profile: "{{ inputs.profile }}"
        confidence_threshold: "{{ inputs.confidence_threshold }}"
        capabilities: "{{ inputs.capabilities }}"
        permissions: "{{ inputs.permissions }}"

  # ===========================================================================
  # STEP 10: Track completion (direct Sql UPDATE)
  # ===========================================================================
  - id: track_done
    type: Sql
    description: Mark phase complete.
    depends_on:
      - block: register_phase
        required: true
      - block: attempt
        required: false
      - block: store_facts
        required: false
      - block: check_conflicts
        required: false
      - block: self_recurse
        required: false
      - block: questions
        required: false
    inputs:
      engine: sqlite
      path: "{{ inputs.state }}"
      sql: |
        UPDATE tasks
        SET status = ?,
            outputs = ?,
            updated_at = datetime('now')
        WHERE id = ?
      params:
        - "{{ 'done' if blocks.attempt.succeeded else 'failed' }}"
        - "{{ {'goal': inputs.pipeline_config.reason.goal | default('explain'), 'success': blocks.attempt.succeeded, 'recursed': blocks.self_recurse.succeeded | default(false), 'questions_spawned': blocks.questions.metadata.count | default(0), 'questions_failed': blocks.questions.metadata.count_failed | default(0), 'facts_stored': blocks.store_facts.metadata.count | default(0), 'facts_recalled': blocks.recall_facts.outputs.row_count | default(0), 'has_conflicts': blocks.check_conflicts.outputs.row_count | default(0) > 0, 'error': blocks.attempt.metadata.message | default('')} | tojson }}"
        - "{{ (blocks.register_phase.outputs.rows | default([{}]))[0].id | default('') }}"

# =============================================================================
# OUTPUTS: synthesis + response + config_override
# =============================================================================
outputs:
  synthesis:
    type: dict
    description: "Unified synthesis. Child's passes through unchanged."
    value: |
      {{ blocks.self_recurse.outputs.synthesis if blocks.self_recurse.succeeded
         else blocks.attempt.outputs.response.synthesis }}

  response:
    type: str
    description: "Direct response to query. Child's passes through unchanged."
    value: |
      {{ blocks.self_recurse.outputs.response if blocks.self_recurse.succeeded
         else blocks.attempt.outputs.response.response }}

  config_override:
    type: dict
    description: "Config override for ACT phase based on discoveries."
    value: |
      {{ blocks.self_recurse.outputs.config_override if blocks.self_recurse.succeeded
         else (blocks.attempt.outputs.response.config_override | default({})) }}

  state:
    type: str
    description: "Path to state database."
    value: "{{ inputs.state }}"
