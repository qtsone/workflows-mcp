# TDD Phase 6: Validation & Quality Gates
#
# Comprehensive quality validation and PRD compliance verification.
#
# This phase ensures production readiness through rigorous quality gates:
# complete test coverage, code quality standards, security scanning,
# performance validation, and full PRD requirement compliance.
#
# Philosophy: Quality is not optional - validate everything before deployment.
#
# Key Activities:
# 1. Run full test suite (unit + integration + E2E)
# 2. Validate overall coverage meets threshold
# 3. Run quality checks (linting, type checking, formatting)
# 4. Validate all quality gates pass
# 5. Run security scanning (bandit, safety)
# 6. Optional performance profiling
# 7. PRD compliance verification
# 8. Generate comprehensive quality report
# 9. Final validation checkpoint
#
# State Management:
# - Reads Phase 5 completion status
# - Stores comprehensive quality metrics
# - Stores PRD compliance percentage
# - Updates phase to phase6_complete
#
# Interactive Pauses:
# - LLM fixes quality gate failures (if needed)
# - LLM verifies PRD requirement compliance
# - Optional performance testing decision
# - Final quality checkpoint
#
# Usage:
#   execute_workflow("tdd-phase6-validation", {
#     "project_path": "/path/to/project",
#     "coverage_threshold": 80
#   })
#
# Output:
#   - All tests passing (unit + integration + E2E)
#   - All quality gates passed
#   - Security scan clean
#   - PRD compliance verified
#   - Ready for production deployment

name: tdd-phase6-validation
description: TDD Phase 6 - Comprehensive quality validation and PRD compliance verification for production readiness
version: "1.0"
author: MCP Workflows Team
tags: [tdd, validation, quality, compliance, security, phase6, production-ready]
inputs:
  project_path:
    type: str
    description: Path to project root directory
    default: "."
    required: false
  state_file:
    type: str
    description: Path to TDD state file (JSON)
    default: ".tdd-state.json"
    required: false
  source_path:
    type: str
    description: Path to source directory (relative to project_path)
    default: "src"
    required: false
  test_path:
    type: str
    description: Path to test directory (relative to project_path)
    default: "tests"
    required: false
  coverage_threshold:
    type: num
    description: Minimum overall code coverage percentage (0-100)
    default: 80
    required: false
  language:
    type: str
    description: Programming language for the project (python, javascript, go, etc.)
    default: "python"
    required: false
  strict_quality:
    type: bool
    description: Enable strict quality mode (fail on warnings)
    default: true
    required: false
  enable_security_scan:
    type: bool
    description: Enable security scanning (bandit, safety)
    default: true
    required: false
blocks:
  - id: read_state
    type: ReadJSONState
    inputs:
      path: "{{inputs.project_path}}/{{inputs.state_file}}"
  - id: validate_phase5_complete
    type: Shell
    inputs:
      command: |
        STATE='{{blocks.read_state.state}}'

        # Check if Phase 5 is in completed phases
        if echo "$STATE" | grep -q '"phase5_complete"'; then
          echo "✅ Phase 5 complete - proceeding with validation"
          exit 0
        else
          echo "❌ ERROR: Phase 5 not complete. Complete integration testing first."
          echo "Current phase: {{blocks.read_state.state.current_phase}}"
          exit 1
        fi
      timeout: 10
    depends_on:
      - read_state
  - id: run_all_tests
    type: Workflow
    inputs:
      workflow: run-tests
      inputs:
        language: "{{inputs.language}}"
        test_path: "{{inputs.test_path}}"
        source_path: "{{inputs.source_path}}"
        coverage_threshold: "{{inputs.coverage_threshold}}"
        working_dir: "{{inputs.project_path}}"
        pytest_args: "-v --tb=short"
    depends_on:
      - validate_phase5_complete
  - id: validate_coverage
    type: Shell
    inputs:
      command: |
        COVERAGE="{{blocks.run_all_tests.outputs.coverage_percent}}"
        THRESHOLD="{{inputs.coverage_threshold}}"

        # Use awk for floating point comparison
        MEETS_THRESHOLD=$(awk -v cov="$COVERAGE" -v thresh="$THRESHOLD" 'BEGIN { print (cov >= thresh) ? "true" : "false" }')

        if [ "$MEETS_THRESHOLD" = "true" ]; then
          echo "✅ Coverage threshold met: ${COVERAGE}% >= ${THRESHOLD}%"
          exit 0
        else
          echo "❌ Coverage threshold NOT met: ${COVERAGE}% < ${THRESHOLD}%"
          echo "Additional test coverage required"
          exit 1
        fi
      timeout: 10
    depends_on:
      - run_all_tests
  - id: run_quality_checks
    type: Workflow
    inputs:
      workflow: quality-check
      inputs:
        language: "{{inputs.language}}"
        source_path: "{{inputs.source_path}}"
        strict: "{{inputs.strict_quality}}"
        working_dir: "{{inputs.project_path}}"
    depends_on:
      - validate_phase5_complete
  - id: validate_quality_gates
    type: Shell
    inputs:
      command: |
        LINTING="{{blocks.run_quality_checks.outputs.linting_passed}}"
        TYPING="{{blocks.run_quality_checks.outputs.typing_passed}}"
        FORMATTING="{{blocks.run_quality_checks.outputs.formatting_passed}}"
        ALL_PASSED="{{blocks.run_quality_checks.outputs.all_checks_passed}}"

        if [ "$ALL_PASSED" = "true" ]; then
          echo "✅ All quality gates PASSED"
          echo "  - Linting: ✓"
          echo "  - Type checking: ✓"
          echo "  - Formatting: ✓"
          exit 0
        else
          echo "❌ Quality gate FAILEDS detected:"
          echo "  - Linting: ${LINTING}"
          echo "  - Type checking: ${TYPING}"
          echo "  - Formatting: ${FORMATTING}"
          echo ""
          echo "Linting output:"
          echo "{{blocks.run_quality_checks.outputs.linting_output}}"
          echo ""
          echo "Type checking output:"
          echo "{{blocks.run_quality_checks.outputs.typing_output}}"
          echo ""
          echo "Formatting output:"
          echo "{{blocks.run_quality_checks.outputs.formatting_output}}"
          exit 1
        fi
      timeout: 10
    depends_on:
      - run_quality_checks
  - id: request_quality_fixes
    type: Prompt
    inputs:
      prompt: |
        === QUALITY GATE FAILEDS: Fixes Required ===

        Quality checks failed. Please analyze and fix:

        Test Results:
        - Tests passing: {{blocks.run_all_tests.outputs.tests_passed}}
        - Tests failing: {{blocks.run_all_tests.outputs.tests_failed}}
        - Coverage: {{blocks.run_all_tests.outputs.coverage_percent}}% (threshold: {{inputs.coverage_threshold}}%)

        Quality Check Results:
        - Linting: {{blocks.run_quality_checks.outputs.linting_passed}}
        - Type checking: {{blocks.run_quality_checks.outputs.typing_passed}}
        - Formatting: {{blocks.run_quality_checks.outputs.formatting_passed}}

        Linting Issues:
        {{blocks.run_quality_checks.outputs.linting_output}}

        Type Checking Issues:
        {{blocks.run_quality_checks.outputs.typing_output}}

        Formatting Issues:
        {{blocks.run_quality_checks.outputs.formatting_output}}

        Provide fixes for ALL failing quality gates.
        Format: filename.py followed by complete corrected content.

        Respond with 'yes' or 'no'
    depends_on:
      - validate_quality_gates
    condition: "{{blocks.validate_quality_gates.failed}}"
  - id: run_bandit_scan
    type: Shell
    inputs:
      command: |
        cd "{{inputs.project_path}}"

        # Check if bandit is available
        if ! command -v bandit &> /dev/null; then
          echo "⚠️  Bandit not installed - skipping security scan"
          echo "Install with: pip install bandit"
          exit 0
        fi

        echo "Running Bandit security scan..."
        bandit -r "{{inputs.source_path}}" -f json -o bandit-report.json || true

        # Check results
        if [ -f bandit-report.json ]; then
          # Parse JSON to check for high/medium severity issues (using python3 for utility script)
          HIGH_ISSUES=$(python3 -c 'import json; data = json.load(open("bandit-report.json")); issues = [i for i in data.get("results", []) if i.get("issue_severity") in ["HIGH", "MEDIUM"]]; print(len(issues))' 2>/dev/null || echo "0")

          if [ "$HIGH_ISSUES" -gt 0 ]; then
            echo "❌ Security issues found: $HIGH_ISSUES high/medium severity"
            bandit -r "{{inputs.source_path}}" -f screen
            exit 1
          else
            echo "✅ No high/medium severity security issues"
            exit 0
          fi
        else
          echo "⚠️  Bandit report not generated"
          exit 0
        fi
      timeout: 300
    depends_on:
      - validate_phase5_complete
    condition: "{{inputs.enable_security_scan}}"
  - id: run_safety_scan
    type: Shell
    inputs:
      command: |
        cd "{{inputs.project_path}}"

        # Check if safety is available
        if ! command -v safety &> /dev/null; then
          echo "⚠️  Safety not installed - skipping dependency scan"
          echo "Install with: pip install safety"
          exit 0
        fi

        echo "Running Safety dependency scan..."

        # Check if requirements.txt exists
        if [ -f requirements.txt ]; then
          safety check -r requirements.txt --json --output safety-report.json || true

          if [ -f safety-report.json ]; then
            # Parse JSON to check for vulnerabilities (using python3 for utility script)
            VULNS=$(python3 -c 'import json; data = json.load(open("safety-report.json")); print(len(data.get("vulnerabilities", [])))' 2>/dev/null || echo "0")

            if [ "$VULNS" -gt 0 ]; then
              echo "❌ Vulnerable dependencies found: $VULNS"
              safety check -r requirements.txt
              exit 1
            else
              echo "✅ No vulnerable dependencies detected"
              exit 0
            fi
          else
            echo "⚠️  Safety report not generated"
            exit 0
          fi
        else
          echo "⚠️  No requirements.txt found - skipping dependency scan"
          exit 0
        fi
      timeout: 300
    depends_on:
      - validate_phase5_complete
    condition: "{{inputs.enable_security_scan}}"
  - id: validate_security
    type: Shell
    inputs:
      command: |
        BANDIT_EXIT="{{blocks.run_bandit_scan.outputs.exit_code}}"
        SAFETY_EXIT="{{blocks.run_safety_scan.outputs.exit_code}}"

        if [ "$BANDIT_EXIT" -eq 0 ] && [ "$SAFETY_EXIT" -eq 0 ]; then
          echo "✅ Security scans PASSED"
          echo "  - Bandit: No critical issues"
          echo "  - Safety: No vulnerable dependencies"
          exit 0
        else
          echo "❌ Security scan FAILEDS:"
          echo "  - Bandit exit code: $BANDIT_EXIT"
          echo "  - Safety exit code: $SAFETY_EXIT"
          exit 1
        fi
      timeout: 10
    depends_on:
      - run_bandit_scan
      - run_safety_scan
    condition: "{{inputs.enable_security_scan}}"
  - id: ask_performance_testing
    type: Prompt
    inputs:
      prompt: |
        Quality gates passed. Would you like to run performance testing?

        Performance testing helps identify:
        - Bottlenecks and slow operations
        - Memory leaks and resource usage
        - Scalability limits
        - Response time characteristics

        Run performance profiling?
    depends_on:
      - validate_quality_gates
      - validate_security
    condition: "{{blocks.validate_quality_gates.succeeded}}"
  - id: request_performance_benchmarks
    type: Prompt
    inputs:
      prompt: |
        === PERFORMANCE TESTING: Define Benchmarks ===

        Please define performance benchmarks and acceptance criteria:

        Considerations:
        1. What are the critical performance paths?
        2. What are acceptable response times?
        3. What are memory usage constraints?
        4. What is the expected scalability (users, requests, data volume)?
        5. Are there any performance SLAs in the PRD?

        Provide:
        1. Performance test scenarios
        2. Acceptance criteria (e.g., "API responds in <100ms for 95% of requests")
        3. Test implementation (if automated)

        If performance testing is not applicable, explain why.
    depends_on:
      - ask_performance_testing
    condition: "{{blocks.ask_performance_testing.response}}.lower().startswith('yes')"
  - id: request_prd_compliance
    type: Prompt
    inputs:
      prompt: |
        === PRD COMPLIANCE VERIFICATION ===

        Verify that ALL PRD requirements have been implemented and tested.

        Review the Technical Specification at: @{{inputs.project_path}}/TECHNICAL_SPEC.md

        Requirements from Phase 1:
        {{blocks.read_state.state.phase1.requirements_count}} requirements defined

        For EACH requirement, indicate:
        - ✅ IMPLEMENTED - Requirement fully met with tests passing
        - ⚠️  PARTIAL - Requirement partially met (explain what's missing)
        - ❌ MISSING - Requirement not implemented

        Provide detailed compliance report:
        1. List each requirement
        2. Implementation status (✅/⚠️/❌)
        3. Test coverage (which tests verify this requirement)
        4. Any deviations or caveats

        Format your response as a structured report.
    depends_on:
      - validate_quality_gates
    condition: "{{blocks.validate_quality_gates.succeeded}}"
  - id: calculate_compliance
    type: Shell
    inputs:
      command: "# Parse LLM response to count compliance\nCOMPLIANCE_TEXT=\"{{blocks.request_prd_compliance.response}}\"\n\n# Count status indicators\nIMPLEMENTED=$(echo \"$COMPLIANCE_TEXT\" | grep -c \"✅ IMPLEMENTED\" || echo \"0\")\nPARTIAL=$(echo \"$COMPLIANCE_TEXT\" | grep -c \"⚠️  PARTIAL\" || echo \"0\")\nMISSING=$(echo \"$COMPLIANCE_TEXT\" | grep -c \"❌ MISSING\" || echo \"0\")\n\nTOTAL=$((IMPLEMENTED + PARTIAL + MISSING))\n\nif [ \"$TOTAL\" -eq 0 ]; then\n  echo \"⚠️  Unable to parse compliance report\"\n  echo \"compliance_percent=0\"\n  exit 0\nfi\n\n# Calculate percentage (full credit for implemented, half credit for partial)\nWEIGHTED=$((IMPLEMENTED * 100 + PARTIAL * 50))\nCOMPLIANCE_PERCENT=$((WEIGHTED / TOTAL))\n\necho \"PRD Compliance Summary:\"\necho \"  ✅ Implemented: $IMPLEMENTED\"\necho \"  ⚠️  Partial: $PARTIAL\"\necho \"  ❌ Missing: $MISSING\"\necho \"  \U0001F4CA Compliance: ${COMPLIANCE_PERCENT}%\"\necho \"\"\necho \"$COMPLIANCE_PERCENT\" > \"{{tmp}}/compliance_percent.txt\"\n"
      timeout: 10
    outputs:
      compliance_percent:
        type: num
        path: "{{tmp}}/compliance_percent.txt"
        description: "PRD compliance percentage (0-100)"
    depends_on:
      - request_prd_compliance
  - id: update_state_phase6
    type: Shell
    inputs:
      command: |
        # Create Python script to update state
        cat > /tmp/update_phase6_state.py << 'PYTHON_SCRIPT'
        import json
        import sys
        from pathlib import Path
        from datetime import datetime

        # Get arguments
        state_file = Path(sys.argv[1])
        total_tests = int(sys.argv[2])
        tests_passing = int(sys.argv[3])
        coverage = float(sys.argv[4])
        linting = sys.argv[5] == 'true'
        typing = sys.argv[6] == 'true'
        formatting = sys.argv[7] == 'true'
        security_bandit = int(sys.argv[8])
        security_safety = int(sys.argv[9])
        compliance_percent = int(sys.argv[10])

        # Read existing state
        state = json.loads(state_file.read_text())

        # Ensure required keys exist
        if 'phases_completed' not in state:
            state['phases_completed'] = []

        # Add phase6_complete to completed phases
        if 'phase6_complete' not in state['phases_completed']:
            state['phases_completed'].append('phase6_complete')

        # Calculate overall quality score
        security_clean = (security_bandit == 0 and security_safety == 0)
        all_quality_gates = linting and typing and formatting

        # Update phase6 metrics
        state['phase6'] = {
            'total_tests': total_tests,
            'tests_passing': tests_passing,
            'overall_coverage': coverage,
            'quality_metrics': {
                'linting': linting,
                'type_checking': typing,
                'formatting': formatting,
                'all_passed': all_quality_gates
            },
            'security_scan': {
                'bandit_exit_code': security_bandit,
                'safety_exit_code': security_safety,
                'clean': security_clean
            },
            'prd_compliance_percent': compliance_percent,
            'all_quality_gates_passed': all_quality_gates,
            'ready_for_deployment': (
                tests_passing == total_tests and
                all_quality_gates and
                security_clean and
                compliance_percent >= 90
            ),
            'completed_at': datetime.now().isoformat()
        }

        # Update current phase
        state['current_phase'] = 'phase6_complete'

        # Write back
        state_file.write_text(json.dumps(state, indent=2) + '\n')

        print(f'✅ Phase 6 complete:')
        print(f'   Tests: {tests_passing}/{total_tests} passing')
        print(f'   Coverage: {coverage}%')
        print(f'   Quality gates: {"✅ PASSED" if all_quality_gates else "❌ FAILED"}')
        print(f'   Security: {"✅ CLEAN" if security_clean else "❌ ISSUES"}')
        print(f'   PRD compliance: {compliance_percent}%')
        print(f'   Ready for deployment: {state["phase6"]["ready_for_deployment"]}')
        PYTHON_SCRIPT

        # Extract compliance percentage from output
        COMPLIANCE="{{blocks.calculate_compliance.outputs.compliance_percent}}"

        # Run the Python script (using python3 for utility script execution)
        python3 /tmp/update_phase6_state.py \
          "{{inputs.project_path}}/{{inputs.state_file}}" \
          "{{blocks.run_all_tests.outputs.tests_passed}}" \
          "{{blocks.run_all_tests.outputs.tests_passed}}" \
          "{{blocks.run_all_tests.outputs.coverage_percent}}" \
          "{{blocks.run_quality_checks.outputs.linting_passed}}" \
          "{{blocks.run_quality_checks.outputs.typing_passed}}" \
          "{{blocks.run_quality_checks.outputs.formatting_passed}}" \
          "{{blocks.run_bandit_scan.outputs.exit_code}}" \
          "{{blocks.run_safety_scan.outputs.exit_code}}" \
          "$COMPLIANCE"
      timeout: 30
    depends_on:
      - calculate_compliance
      - run_all_tests
      - run_quality_checks
      - run_bandit_scan
      - run_safety_scan
  - id: final_quality_checkpoint
    type: Prompt
    inputs:
      prompt: |
        ╔════════════════════════════════════════════════════════════════╗
        ║          PHASE 6: QUALITY VALIDATION COMPLETE                 ║
        ╚════════════════════════════════════════════════════════════════╝

        Test Suite Results:
        - Total tests: {{blocks.run_all_tests.outputs.tests_passed}}
        - Tests passing: {{blocks.run_all_tests.outputs.tests_passed}}
        - Overall coverage: {{blocks.run_all_tests.outputs.coverage_percent}}%
        - Threshold: {{inputs.coverage_threshold}}%

        Quality Gates:
        - Linting: {{blocks.run_quality_checks.outputs.linting_passed}}
        - Type checking: {{blocks.run_quality_checks.outputs.typing_passed}}
        - Formatting: {{blocks.run_quality_checks.outputs.formatting_passed}}
        - Overall: {{blocks.run_quality_checks.outputs.all_checks_passed}}

        Security Scan:
        - Bandit: {{blocks.run_bandit_scan.outputs.exit_code}}
        - Safety: {{blocks.run_safety_scan.outputs.exit_code}}

        PRD Compliance:
        - {{blocks.calculate_compliance.outputs.stdout}}

        All quality gates passed. System is production-ready.

        Approve Phase 6 completion and deployment readiness?

        Respond with 'yes' or 'no'

        Respond with 'yes' or 'no'
      operation: "phase6_quality_checkpoint"
      details:
        tests_passing: "{{blocks.run_all_tests.outputs.tests_passed}}"
        coverage: "{{blocks.run_all_tests.outputs.coverage_percent}}%"
        quality_gates: "{{blocks.run_quality_checks.outputs.all_checks_passed}}"
        security_clean: "{{blocks.validate_security.outputs.exit_code}} == 0"
        prd_compliance: "{{blocks.calculate_compliance.outputs.stdout}}"
    depends_on:
      - update_state_phase6
  - id: generate_quality_report
    type: Shell
    inputs:
      command: |
        cat > "{{inputs.project_path}}/QUALITY_REPORT.md" << 'EOF'
        # Quality Validation Report

        **Generated**: $(date -Iseconds)
        **Phase**: Phase 6 - Validation & Quality
        **Status**: {{blocks.final_quality_checkpoint.outputs.response}} == 'yes'

        ## Test Results

        - **Total Tests**: {{blocks.run_all_tests.outputs.tests_passed}}
        - **Tests Passing**: {{blocks.run_all_tests.outputs.tests_passed}}
        - **Tests Failing**: {{blocks.run_all_tests.outputs.tests_failed}}
        - **Overall Coverage**: {{blocks.run_all_tests.outputs.coverage_percent}}%
        - **Coverage Threshold**: {{inputs.coverage_threshold}}%

        ## Quality Metrics

        | Check | Status | Exit Code |
        |-------|--------|-----------|
        | Linting (ruff) | {{blocks.run_quality_checks.outputs.linting_passed}} | {{blocks.run_quality_checks.outputs.linting_exit_code}} |
        | Type Checking (mypy) | {{blocks.run_quality_checks.outputs.typing_passed}} | {{blocks.run_quality_checks.outputs.typing_exit_code}} |
        | Formatting (ruff format) | {{blocks.run_quality_checks.outputs.formatting_passed}} | {{blocks.run_quality_checks.outputs.formatting_exit_code}} |

        ## Security Scan

        - **Bandit (Code Security)**: Exit Code {{blocks.run_bandit_scan.outputs.exit_code}}
        - **Safety (Dependencies)**: Exit Code {{blocks.run_safety_scan.outputs.exit_code}}

        ## PRD Compliance

        {{blocks.calculate_compliance.outputs.stdout}}

        ## Deployment Readiness

        **Production Ready**: {{blocks.final_quality_checkpoint.outputs.response}} == 'yes'

        All quality gates have been validated and the system is ready for deployment.

        EOF

        echo "✅ Quality report generated: {{inputs.project_path}}/QUALITY_REPORT.md"
      timeout: 30
    depends_on:
      - final_quality_checkpoint
  - id: phase6_summary
    type: Shell
    inputs:
      command: "echo \"╔════════════════════════════════════════════════════════════════╗\"\necho \"║       TDD PHASE 6: QUALITY VALIDATION COMPLETE                ║\"\necho \"╚════════════════════════════════════════════════════════════════╝\"\necho \"\"\necho \"Test Results:\"\necho \"  ✅ Total tests: {{blocks.run_all_tests.outputs.tests_passed}}\"\necho \"  \U0001F4CA Coverage: {{blocks.run_all_tests.outputs.coverage_percent}}% (threshold: {{inputs.coverage_threshold}}%)\"\necho \"\"\necho \"Quality Gates:\"\necho \"  ✓ Linting: {{blocks.run_quality_checks.outputs.linting_passed}}\"\necho \"  ✓ Type checking: {{blocks.run_quality_checks.outputs.typing_passed}}\"\necho \"  ✓ Formatting: {{blocks.run_quality_checks.outputs.formatting_passed}}\"\necho \"\"\necho \"Security:\"\necho \"  ✓ Bandit: {{blocks.run_bandit_scan.outputs.exit_code}}\"\necho \"  ✓ Safety: {{blocks.run_safety_scan.outputs.exit_code}}\"\necho \"\"\necho \"PRD Compliance:\"\necho \"  {{blocks.calculate_compliance.outputs.stdout}}\"\necho \"\"\necho \"Files Created:\"\necho \"  - {{inputs.project_path}}/QUALITY_REPORT.md\"\necho \"  - {{inputs.project_path}}/{{inputs.state_file}} (updated)\"\necho \"\"\necho \"\U0001F389 PRODUCTION READY - All quality gates passed!\"\n"
      timeout: 10
    depends_on:
      - generate_quality_report
outputs:
  # Test metrics
  total_tests:
    value: "{{blocks.run_all_tests.outputs.tests_passed}}"
  tests_passing:
    value: "{{blocks.run_all_tests.outputs.tests_passed}}"
  tests_failing:
    value: "{{blocks.run_all_tests.outputs.tests_failed}}"
  overall_coverage:
    value: "{{blocks.run_all_tests.outputs.coverage_percent}}"
  # Quality gate results
  linting_passed:
    value: "{{blocks.run_quality_checks.outputs.linting_passed}}"
  type_checking_passed:
    value: "{{blocks.run_quality_checks.outputs.typing_passed}}"
  formatting_passed:
    value: "{{blocks.run_quality_checks.outputs.formatting_passed}}"
  all_quality_gates_passed:
    value: "{{blocks.run_quality_checks.outputs.all_checks_passed}}"
  # Security scan results
  security_bandit_exit_code:
    value: "{{blocks.run_bandit_scan.outputs.exit_code}}"
  security_safety_exit_code:
    value: "{{blocks.run_safety_scan.outputs.exit_code}}"
  security_scan_clean:
    value: "{{blocks.validate_security.succeeded}}"
  # PRD compliance
  prd_compliance:
    value: "{{blocks.calculate_compliance.outputs.stdout}}"
  # Overall status
  all_gates_passed:
    value: "{{blocks.validate_quality_gates.succeeded}} and {{blocks.validate_security.succeeded}}"
  production_ready:
    value: "{{blocks.final_quality_checkpoint.outputs.response}} == 'yes'"
  # Checkpoint
  checkpoint_approved:
    value: "{{blocks.final_quality_checkpoint.outputs.response}} == 'yes'"
  # State and reports
  state_updated:
    value: "{{blocks.update_state_phase6.succeeded}}"
  quality_report_path:
    value: "{{inputs.project_path}}/QUALITY_REPORT.md"
  # Summary
  summary:
    value: "{{blocks.phase6_summary.outputs.stdout}}"
